apiVersion: batch/v1
kind: Job
metadata:
  name: comfyui-model-bootstrap
  namespace: ai-stack
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation,HookSucceeded
spec:
  backoffLimit: 2
  ttlSecondsAfterFinished: 300
  template:
    spec:
      nodeSelector:
        gpu: "true"
      affinity:
        podAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - comfyui
              topologyKey: kubernetes.io/hostname
      tolerations:
        - key: "node-role.kubernetes.io/control-plane"
          operator: "Exists"
          effect: "NoSchedule"
      restartPolicy: OnFailure
      containers:
        - name: bootstrap
          image: python:3.12-alpine
          env:
            - name: COMFYUI_BASE_DIR
              value: "/comfy-pvc/basedir"
            - name: COMFYUI_MODEL_URLS_FILE
              value: "/config/huggingface-urls.txt"
            - name: COMFYUI_MODEL_REPOS_FILE
              value: "/config/huggingface-repos.txt"
            - name: COMFYUI_MODEL_NAMES_FILE
              value: "/config/model-names.yaml"
            - name: COMFYUI_PREFETCH_ATTEMPTS
              value: "8"
            - name: COMFYUI_HTTP_TIMEOUT_SECONDS
              value: "120"
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: localai-model-downloads
                  key: hf_token
                  optional: true
          volumeMounts:
            - name: comfyui-data
              mountPath: /comfy-pvc
            - name: model-config
              mountPath: /config
              readOnly: true
          command:
            - /bin/sh
            - -lc
          args:
            - |
              python - <<'PY'
              import json
              import os
              import re
              import subprocess
              import sys
              import time
              import urllib.error
              import urllib.parse
              import urllib.request

              base_dir = os.getenv("COMFYUI_BASE_DIR", "/comfy-pvc/basedir").rstrip("/")
              models_root = os.path.join(base_dir, "models")
              user_root = os.path.join(base_dir, "user")
              urls_file = os.getenv("COMFYUI_MODEL_URLS_FILE", "/config/huggingface-urls.txt").strip()
              repos_file = os.getenv("COMFYUI_MODEL_REPOS_FILE", "/config/huggingface-repos.txt").strip()
              names_file = os.getenv("COMFYUI_MODEL_NAMES_FILE", "/config/model-names.yaml").strip()
              prefetch_attempts = int(os.getenv("COMFYUI_PREFETCH_ATTEMPTS", "8"))
              http_timeout_seconds = int(os.getenv("COMFYUI_HTTP_TIMEOUT_SECONDS", "120"))
              hf_token = os.getenv("HF_TOKEN", "").strip()

              comfyui_dirs = {
                  "audio_encoders",
                  "checkpoints",
                  "classifiers",
                  "clip",
                  "clip_vision",
                  "configs",
                  "controlnet",
                  "diffusers",
                  "diffusion_models",
                  "embeddings",
                  "gligen",
                  "hypernetworks",
                  "latent_upscale_models",
                  "loras",
                  "model_patches",
                  "photomaker",
                  "style_models",
                  "text_encoders",
                  "unet",
                  "upscale_models",
                  "vae",
                  "vae_approx",
              }

              folder_aliases = {
                  "checkpoint": "checkpoints",
                  "checkpoints": "checkpoints",
                  "ckpt": "checkpoints",
                  "lora": "loras",
                  "loras": "loras",
                  "controlnet": "controlnet",
                  "control_net": "controlnet",
                  "vae": "vae",
                  "diffuser": "diffusers",
                  "diffusers": "diffusers",
                  "upscale": "upscale_models",
                  "upscalers": "upscale_models",
                  "upscale_models": "upscale_models",
                  "embeddings": "embeddings",
                  "clip_vision": "clip_vision",
                  "text_encoders": "text_encoders",
              }

              file_extensions = {
                  ".safetensors",
                  ".ckpt",
                  ".pt",
                  ".pth",
                  ".bin",
              }

              def ensure_dir(path):
                  os.makedirs(path, exist_ok=True)

              def safe_join(root, *parts):
                  root_abs = os.path.abspath(root)
                  candidate = os.path.abspath(os.path.join(root_abs, *parts))
                  if candidate != root_abs and not candidate.startswith(root_abs + os.sep):
                      raise RuntimeError(f"Invalid path traversal for root={root_abs}, parts={parts}")
                  return candidate

              def sanitize_name(raw):
                  text = str(raw or "").strip()
                  text = re.sub(r"[^A-Za-z0-9._-]+", "_", text)
                  return text.strip("._-") or "model"

              def normalize_folder(value):
                  if value is None:
                      return None
                  text = str(value).strip().lower().replace("-", "_")
                  text = folder_aliases.get(text, text)
                  if text in comfyui_dirs:
                      return text
                  return None

              def read_entries_from_file(file_path, label):
                  if not file_path:
                      return []
                  if not os.path.exists(file_path):
                      print(f"{label} file not found: {file_path} (skipping)", flush=True)
                      return []
                  entries = []
                  with open(file_path, "r", encoding="utf-8") as handle:
                      for raw_line in handle:
                          line = raw_line.strip()
                          if not line or line.startswith("#"):
                              continue
                          entries.append(line)
                  return entries

              def parse_url_spec(spec):
                  if "->" in spec:
                      url, target = spec.split("->", 1)
                      return url.strip(), target.strip()
                  return spec.strip(), ""

              def parse_repo_spec(spec):
                  repo_spec = spec
                  target_dir = ""

                  if "->" in spec:
                      repo_spec, target_dir = spec.split("->", 1)
                      repo_spec = repo_spec.strip()
                      target_dir = target_dir.strip()

                  revision = None
                  if "@" in repo_spec:
                      repo_id, revision = repo_spec.rsplit("@", 1)
                      repo_id = repo_id.strip()
                      revision = revision.strip() or None
                  else:
                      repo_id = repo_spec.strip()

                  if not repo_id:
                      raise RuntimeError(f"Invalid repo spec: {spec}")

                  if not target_dir:
                      target_dir = repo_id.rsplit("/", 1)[-1]
                  target_dir = sanitize_name(os.path.basename(target_dir.strip("/")))
                  return repo_id, revision, target_dir

              def get_yaml_module():
                  try:
                      import yaml
                      return yaml
                  except Exception:
                      print("Installing PyYAML...", flush=True)
                      install = subprocess.run(
                          [sys.executable, "-m", "pip", "install", "--no-cache-dir", "PyYAML"],
                          capture_output=True,
                          text=True,
                      )
                      if install.returncode != 0:
                          raise RuntimeError(f"Failed to install PyYAML: {install.stderr.strip()}")
                      import yaml
                      return yaml

              def read_model_name_entries():
                  if not names_file or not os.path.exists(names_file):
                      print(f"Model name mapping file not found: {names_file} (skipping)", flush=True)
                      return []

                  yaml = get_yaml_module()
                  with open(names_file, "r", encoding="utf-8") as handle:
                      payload = yaml.safe_load(handle) or {}

                  if isinstance(payload, list):
                      raw_entries = payload
                  elif isinstance(payload, dict):
                      if isinstance(payload.get("models"), list):
                          raw_entries = payload["models"]
                      elif isinstance(payload.get("entries"), list):
                          raw_entries = payload["entries"]
                      else:
                          raw_entries = []
                  else:
                      raw_entries = []

                  entries = []
                  for item in raw_entries:
                      if not isinstance(item, dict):
                          continue
                      model_id = str(item.get("id", "")).strip()
                      model_path = str(item.get("model", "")).strip()
                      if not model_id or not model_path:
                          continue
                      normalized = dict(item)
                      normalized["id"] = model_id
                      normalized["model"] = model_path
                      entries.append(normalized)
                  return entries

              def best_entry_match(entries, *candidates):
                  normalized_candidates = []
                  for candidate in candidates:
                      if not candidate:
                          continue
                      text = str(candidate).strip()
                      if not text:
                          continue
                      normalized_candidates.append(text)
                      normalized_candidates.append(os.path.basename(text))
                  lowered = {value.lower() for value in normalized_candidates}
                  for entry in entries:
                      fields = {
                          entry.get("id", ""),
                          entry.get("model", ""),
                          os.path.basename(str(entry.get("model", ""))),
                      }
                      if any(str(field).lower() in lowered for field in fields if field):
                          return entry
                  return None

              def infer_folder(entry, hint_text, is_repo):
                  for key in (
                      "comfyui_folder",
                      "comfyui_subdir",
                      "folder",
                      "target_folder",
                      "comfy_folder",
                      "comfy_target",
                  ):
                      folder = normalize_folder(entry.get(key) if entry else None)
                      if folder:
                          return folder

                  lowered = str(hint_text or "").lower()
                  backend = str(entry.get("backend", "") if entry else "").strip().lower()
                  extension = os.path.splitext(lowered)[1]

                  if "lora" in lowered:
                      return "loras"
                  if "controlnet" in lowered or "control_net" in lowered:
                      return "controlnet"
                  if "vae" in lowered:
                      return "vae"
                  if "upscale" in lowered:
                      return "upscale_models"
                  if "embed" in lowered:
                      return "embeddings"

                  if is_repo:
                      if backend == "diffusers":
                          return "diffusers"
                      return "diffusers"

                  if extension in file_extensions:
                      return "checkpoints"
                  return "checkpoints"

              def parse_target_override(raw_target):
                  target = str(raw_target or "").strip()
                  if not target:
                      return None, None
                  parts = [part for part in target.split("/") if part]
                  if len(parts) >= 2:
                      folder = normalize_folder(parts[0])
                      if folder:
                          name = sanitize_name("/".join(parts[1:]))
                          return folder, name
                  folder_only = normalize_folder(target)
                  if folder_only:
                      return folder_only, None
                  return None, sanitize_name(target)

              def get_snapshot_download():
                  try:
                      from huggingface_hub import snapshot_download
                      return snapshot_download
                  except Exception:
                      print("Installing huggingface_hub...", flush=True)
                      install = subprocess.run(
                          [sys.executable, "-m", "pip", "install", "--no-cache-dir", "huggingface_hub"],
                          capture_output=True,
                          text=True,
                      )
                      if install.returncode != 0:
                          raise RuntimeError(
                              f"Failed to install huggingface_hub: {install.stderr.strip()}"
                          )
                      from huggingface_hub import snapshot_download
                      return snapshot_download

              def auth_headers_for_url(url):
                  parsed = urllib.parse.urlparse(url)
                  if hf_token and "huggingface.co" in parsed.netloc.lower():
                      return {"Authorization": f"Bearer {hf_token}"}
                  return {}

              def download_file(url, target_path, attempts):
                  ensure_dir(os.path.dirname(target_path))
                  if os.path.exists(target_path) and os.path.getsize(target_path) > 0:
                      print(f"File already exists, skipping: {target_path}", flush=True)
                      return

                  temp_path = f"{target_path}.partial"
                  headers = auth_headers_for_url(url)
                  last_error = None
                  for attempt in range(1, attempts + 1):
                      try:
                          print(
                              f"Downloading {url} -> {target_path} (attempt {attempt}/{attempts})",
                              flush=True,
                          )
                          request = urllib.request.Request(url, headers=headers)
                          with urllib.request.urlopen(request, timeout=http_timeout_seconds) as response:
                              with open(temp_path, "wb") as out:
                                  while True:
                                      chunk = response.read(1024 * 1024)
                                      if not chunk:
                                          break
                                      out.write(chunk)
                          os.replace(temp_path, target_path)
                          print(f"Download complete: {target_path}", flush=True)
                          return
                      except Exception as exc:
                          last_error = exc
                          print(f"Download failed: {exc}", flush=True)
                          if attempt < attempts:
                              time.sleep(10)
                  raise RuntimeError(f"Failed to download {url}: {last_error}")

              def download_repo_snapshot(snapshot_download, repo_id, revision, target_path, attempts):
                  ensure_dir(target_path)
                  last_error = None
                  for attempt in range(1, attempts + 1):
                      try:
                          print(
                              f"Snapshot {repo_id}{'@' + revision if revision else ''} -> {target_path} (attempt {attempt}/{attempts})",
                              flush=True,
                          )
                          kwargs = {
                              "repo_id": repo_id,
                              "local_dir": target_path,
                              "resume_download": True,
                          }
                          if revision:
                              kwargs["revision"] = revision
                          if hf_token:
                              kwargs["token"] = hf_token
                          snapshot_download(**kwargs)
                          print(f"Snapshot complete: {target_path}", flush=True)
                          return
                      except Exception as exc:
                          last_error = exc
                          print(f"Snapshot failed: {exc}", flush=True)
                          if attempt < attempts:
                              time.sleep(10)
                  raise RuntimeError(f"Failed to snapshot repo {repo_id}: {last_error}")

              def create_alias_if_needed(target_path, alias_path):
                  if not alias_path or os.path.abspath(target_path) == os.path.abspath(alias_path):
                      return
                  if os.path.exists(alias_path) or os.path.islink(alias_path):
                      return
                  try:
                      rel_target = os.path.relpath(target_path, os.path.dirname(alias_path))
                      os.symlink(rel_target, alias_path)
                      print(f"Created alias symlink: {alias_path} -> {rel_target}", flush=True)
                  except Exception as exc:
                      print(f"Unable to create alias symlink {alias_path}: {exc}", flush=True)

              ensure_dir(base_dir)
              ensure_dir(models_root)
              ensure_dir(user_root)
              for directory in sorted(comfyui_dirs):
                  ensure_dir(os.path.join(models_root, directory))

              model_entries = read_model_name_entries()
              extra_urls = read_entries_from_file(urls_file, "Extra model URL")
              repo_specs = read_entries_from_file(repos_file, "Extra model repo")

              print(
                  f"Loaded config: model_entries={len(model_entries)} urls={len(extra_urls)} repos={len(repo_specs)}",
                  flush=True,
              )

              index = {
                  "generated_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                  "base_dir": base_dir,
                  "models_root": models_root,
                  "entries": [],
              }

              for spec in extra_urls:
                  url, explicit_target = parse_url_spec(spec)
                  parsed = urllib.parse.urlparse(url)
                  file_name = sanitize_name(os.path.basename(urllib.parse.unquote(parsed.path)))
                  if not file_name:
                      raise RuntimeError(f"Unable to determine file name from URL: {url}")

                  entry = best_entry_match(model_entries, file_name, os.path.splitext(file_name)[0])
                  override_folder, override_name = parse_target_override(explicit_target)
                  hint = " ".join(
                      value
                      for value in (
                          file_name,
                          explicit_target,
                          entry.get("id", "") if entry else "",
                          entry.get("model", "") if entry else "",
                      )
                      if value
                  )
                  folder = override_folder or infer_folder(entry, hint, is_repo=False)
                  name = override_name or file_name

                  target_path = safe_join(models_root, folder, name)
                  download_file(url, target_path, prefetch_attempts)

                  index["entries"].append(
                      {
                          "source_type": "url",
                          "source": url,
                          "id": entry.get("id", "") if entry else "",
                          "folder": folder,
                          "path": target_path,
                      }
                  )

              if repo_specs:
                  snapshot_download = get_snapshot_download()
              else:
                  snapshot_download = None

              for spec in repo_specs:
                  repo_id, revision, target_name = parse_repo_spec(spec)
                  entry = best_entry_match(model_entries, repo_id, target_name)
                  hint = " ".join(
                      value
                      for value in (
                          repo_id,
                          target_name,
                          entry.get("id", "") if entry else "",
                          entry.get("model", "") if entry else "",
                      )
                      if value
                  )
                  folder = infer_folder(entry, hint, is_repo=True)
                  primary_name = target_name
                  target_path = safe_join(models_root, folder, primary_name)
                  download_repo_snapshot(
                      snapshot_download,
                      repo_id,
                      revision,
                      target_path,
                      prefetch_attempts,
                  )

                  alias_id = sanitize_name(entry.get("id")) if entry else ""
                  if alias_id and alias_id != primary_name:
                      alias_path = safe_join(models_root, folder, alias_id)
                      create_alias_if_needed(target_path, alias_path)

                  index["entries"].append(
                      {
                          "source_type": "repo",
                          "source": repo_id,
                          "revision": revision or "",
                          "id": entry.get("id", "") if entry else "",
                          "folder": folder,
                          "path": target_path,
                      }
                  )

              index_path = os.path.join(user_root, "comfyui-model-sync.json")
              with open(index_path, "w", encoding="utf-8") as handle:
                  json.dump(index, handle, indent=2)
              print(f"Wrote model sync index: {index_path}", flush=True)
              print("ComfyUI model bootstrap complete", flush=True)
              PY
      volumes:
        - name: comfyui-data
          persistentVolumeClaim:
            claimName: comfyui-data
        - name: model-config
          projected:
            sources:
              - secret:
                  name: localai-model-downloads
                  optional: true
              - secret:
                  name: localai-model-names
                  optional: true
