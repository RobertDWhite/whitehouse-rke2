apiVersion: v1
data:
  audio.py: |
    import numpy as np
    import librosa
    import librosa.display
    import matplotlib
    matplotlib.use("Agg")
    import matplotlib.pyplot as plt


    def generate_waveform_peaks(audio_path: str, num_peaks: int = 1000) -> dict:
        """Generate waveform peaks for visualization.

        Returns a dict with:
        - peaks: list of [min, max] values per segment
        - duration: total duration in seconds
        - sample_rate: original sample rate
        """
        # Load audio
        y, sr = librosa.load(audio_path, sr=None, mono=True)
        duration = len(y) / sr

        # Calculate samples per peak
        samples_per_peak = max(1, len(y) // num_peaks)

        peaks = []
        for i in range(0, len(y), samples_per_peak):
            segment = y[i : i + samples_per_peak]
            if len(segment) > 0:
                peaks.append([float(np.min(segment)), float(np.max(segment))])

        return {
            "peaks": peaks,
            "duration": duration,
            "sample_rate": sr,
            "num_samples": len(y),
        }


    def generate_spectrogram(
        audio_path: str,
        output_path: str,
        figsize: tuple = (12, 4),
        max_seconds: int = 90,
    ):
        """Generate spectrogram image and save to file."""
        # Bound decode duration to avoid huge memory/latency on very long captures.
        y, sr = librosa.load(audio_path, sr=8000, mono=True, duration=max_seconds)

        # Compute spectrogram
        hop_length = max(256, len(y) // 2000) if len(y) else 256
        D = librosa.amplitude_to_db(
            np.abs(librosa.stft(y, n_fft=512, hop_length=hop_length)),
            ref=np.max,
        )

        # Create figure
        fig, ax = plt.subplots(figsize=figsize)
        img = librosa.display.specshow(D, sr=sr, x_axis="time", y_axis="hz", ax=ax, cmap="magma")
        ax.set_xlabel("Time (s)")
        ax.set_ylabel("Frequency (Hz)")
        fig.colorbar(img, ax=ax, format="%+2.0f dB")

        # Save
        plt.tight_layout()
        plt.savefig(output_path, dpi=100, bbox_inches="tight", pad_inches=0.1)
        plt.close(fig)


    def get_time_segments(transcript: str, duration: float) -> list:
        """Estimate time segments for transcript words.

        Since Whisper doesn't always provide word-level timestamps in our setup,
        we estimate based on character position and total duration.
        """
        if not transcript:
            return []

        words = transcript.split()
        total_chars = len(transcript)
        if total_chars == 0:
            return []

        segments = []
        char_pos = 0
        for word in words:
            start_time = (char_pos / total_chars) * duration
            char_pos += len(word) + 1  # +1 for space
            end_time = (char_pos / total_chars) * duration
            segments.append({
                "word": word,
                "start": start_time,
                "end": end_time,
            })

        return segments


    def compute_signal_db(audio_path: str):
        """Compute RMS signal level in dBFS for a WAV file."""
        try:
            y, sr = librosa.load(audio_path, sr=None, mono=True)
            rms = float(np.sqrt(np.mean(y ** 2)))
            return round(20 * np.log10(rms), 1) if rms > 0 else None
        except Exception:
            return None
  files.py: |
    import io
    import os
    import zipfile
    from datetime import datetime, timedelta
    from typing import Optional, List

    from fastapi import APIRouter, Depends, HTTPException, Query, Request
    from fastapi.responses import StreamingResponse, FileResponse
    from pydantic import BaseModel
    from sqlalchemy import desc, func, or_, text as sql_text
    from sqlalchemy.orm import Session

    from ..database import get_db
    from ..models import CallsignInfo, Recording, Repeater
    from ..services.tagging import extract_callsign_tags, normalize_callsign, parse_ai_tags

    router = APIRouter()


    class UpdateRecordingRequest(BaseModel):
        ai_tags: Optional[List[str]] = None
        transcript: Optional[str] = None


    class BulkDeleteRequest(BaseModel):
        ids: List[int]


    class BulkDeleteFilteredRequest(BaseModel):
        mode: Optional[str] = None
        frequency_min: Optional[float] = None
        frequency_max: Optional[float] = None
        q: Optional[str] = None
        callsign: Optional[str] = None
        date_from: Optional[datetime] = None
        date_to: Optional[datetime] = None
        duration_min: Optional[float] = None
        duration_max: Optional[float] = None
        has_transcript: Optional[bool] = None
        dry_run: bool = False


    def _validate_mode(mode: Optional[str]):
        if mode is not None and mode not in {"cw", "voice"}:
            raise HTTPException(status_code=422, detail="mode must be 'cw' or 'voice'")


    def _validate_duration_bounds(duration_min: Optional[float], duration_max: Optional[float]):
        if (
            duration_min is not None
            and duration_max is not None
            and duration_min > duration_max
        ):
            raise HTTPException(
                status_code=422,
                detail="duration_min cannot be greater than duration_max",
            )


    def _all_tags(callsign_tags: List[str], ai_tags: List[str]) -> List[str]:
        return list(dict.fromkeys(callsign_tags + ai_tags))


    def _apply_recording_filters(
        query,
        mode: Optional[str] = None,
        frequency_min: Optional[float] = None,
        frequency_max: Optional[float] = None,
        q: Optional[str] = None,
        callsign: Optional[str] = None,
        date_from: Optional[datetime] = None,
        date_to: Optional[datetime] = None,
        duration_min: Optional[float] = None,
        duration_max: Optional[float] = None,
        has_transcript: Optional[bool] = None,
    ):
        if mode:
            query = query.filter(Recording.mode == mode)
        if frequency_min is not None:
            query = query.filter(Recording.frequency_hz >= frequency_min)
        if frequency_max is not None:
            query = query.filter(Recording.frequency_hz <= frequency_max)

        if q:
            cleaned_q = q.strip()
            if cleaned_q:
                search_query = func.plainto_tsquery("english", cleaned_q)
                query = query.filter(
                    or_(
                        Recording.search_vector.op("@@")(search_query),
                        Recording.transcript.ilike(f"%{cleaned_q}%"),
                    )
                )

        if callsign:
            normalized_callsign = normalize_callsign(callsign)
            if normalized_callsign:
                normalized_transcript = func.regexp_replace(
                    func.upper(func.coalesce(Recording.transcript, "")),
                    "[^A-Z0-9]+",
                    "",
                    "g",
                )
                query = query.filter(normalized_transcript.ilike(f"%{normalized_callsign}%"))

        if date_from:
            query = query.filter(Recording.timestamp >= date_from)
        if date_to:
            query = query.filter(Recording.timestamp <= date_to)
        if duration_min is not None:
            query = query.filter(Recording.duration_seconds >= duration_min)
        if duration_max is not None:
            query = query.filter(Recording.duration_seconds <= duration_max)

        transcript_len = func.length(func.trim(func.coalesce(Recording.transcript, "")))
        if has_transcript is True:
            query = query.filter(transcript_len > 0)
        elif has_transcript is False:
            query = query.filter(transcript_len == 0)

        return query


    def _apply_tag_filter(query, tag: Optional[str]):
        """Filter by an AI or callsign tag substring present in the JSON tags list."""
        if not tag:
            return query
        cleaned = tag.strip().lower()
        if not cleaned:
            return query
        # ai_tags is a JSON-encoded list like ["repeater","W3RDW","voice"]
        # Match tag as a JSON string element, case-insensitive.
        query = query.filter(Recording.ai_tags.ilike(f'%"{cleaned}"%'))
        return query


    @router.get("/browse")
    async def browse_files(
        mode: Optional[str] = Query(None, pattern="^(cw|voice)$"),
        frequency_min: Optional[float] = None,
        frequency_max: Optional[float] = None,
        q: Optional[str] = Query(None, min_length=1),
        callsign: Optional[str] = Query(None, min_length=1, max_length=20),
        tag: Optional[str] = Query(None, min_length=1, max_length=50),
        repeater: Optional[str] = Query(None, min_length=1, max_length=20),
        date_from: Optional[datetime] = None,
        date_to: Optional[datetime] = None,
        duration_min: Optional[float] = Query(None, ge=0),
        duration_max: Optional[float] = Query(None, ge=0),
        has_transcript: Optional[bool] = None,
        page: int = Query(1, ge=1),
        limit: int = Query(50, ge=1, le=200),
        db: Session = Depends(get_db),
    ):
        """List recordings with optional filters. APRS is excluded — use the APRS tab."""
        _validate_duration_bounds(duration_min, duration_max)

        query = _apply_recording_filters(
            db.query(Recording),
            mode=mode,
            frequency_min=frequency_min,
            frequency_max=frequency_max,
            q=q,
            callsign=callsign,
            date_from=date_from,
            date_to=date_to,
            duration_min=duration_min,
            duration_max=duration_max,
            has_transcript=has_transcript,
        )
        if not mode and not callsign:
            query = query.filter(Recording.mode != "aprs")
        query = _apply_tag_filter(query, tag)

        if repeater:
            query = (
                query
                .join(Repeater, Recording.repeater_id == Repeater.id)
                .filter(Repeater.callsign.ilike(f"%{repeater.strip().upper()}%"))
            )

        total = query.count()
        recordings = (
            query.order_by(desc(Recording.timestamp))
            .offset((page - 1) * limit)
            .limit(limit)
            .all()
        )

        return {
            "total": total,
            "page": page,
            "limit": limit,
            "items": [
                {
                    "id": r.id,
                    "filename": r.filename,
                    "mode": r.mode,
                    "frequency_hz": r.frequency_hz,
                    "frequency_label": r.frequency_label,
                    "timestamp": r.timestamp.isoformat() if r.timestamp else None,
                    "duration_seconds": r.duration_seconds,
                    "has_transcript": bool((r.transcript or "").strip()),
                    "signal_db": r.signal_db,
                    "callsign_tags": (callsign_tags := extract_callsign_tags(r.transcript)),
                    "ai_tags": (ai_tags := parse_ai_tags(r.ai_tags)),
                    "tags": _all_tags(callsign_tags, ai_tags),
                }
                for r in recordings
            ],
        }


    @router.get("/callsign/{callsign}")
    async def get_callsign_info(callsign: str, db: Session = Depends(get_db)):
        """Return operator info and recording statistics for a callsign."""
        cs = callsign.strip().upper()
        # Strip SSID (e.g. KE8WSC-8 → KE8WSC) for operator DB lookup
        base_cs = re.sub(r"-\w+$", "", cs)
        info = (
            db.query(CallsignInfo).filter(CallsignInfo.callsign == cs).first()
            or db.query(CallsignInfo).filter(CallsignInfo.callsign == base_cs).first()
        )
        normalized_cs = normalize_callsign(cs)
        total = 0
        first_heard = None
        last_heard = None
        total_airtime = 0.0
        if normalized_cs:
            normalized_transcript = func.regexp_replace(
                func.upper(func.coalesce(Recording.transcript, "")),
                "[^A-Z0-9]+",
                "",
                "g",
            )
            base_q = db.query(Recording).filter(
                normalized_transcript.ilike(f"%{normalized_cs}%")
            )
            total = base_q.count()
            first_heard = (
                db.query(func.min(Recording.timestamp))
                .filter(normalized_transcript.ilike(f"%{normalized_cs}%"))
                .scalar()
            )
            last_heard = (
                db.query(func.max(Recording.timestamp))
                .filter(normalized_transcript.ilike(f"%{normalized_cs}%"))
                .scalar()
            )
            total_airtime = (
                db.query(func.sum(Recording.duration_seconds))
                .filter(normalized_transcript.ilike(f"%{normalized_cs}%"))
                .scalar()
            ) or 0.0
        return {
            "callsign": cs,
            "operator": {
                "name": info.name,
                "qth_city": info.qth_city,
                "qth_state": info.qth_state,
                "license_class": info.license_class,
                "grid": info.grid,
            } if info else None,
            "total_recordings": total,
            "first_heard": first_heard.isoformat() if first_heard else None,
            "last_heard": last_heard.isoformat() if last_heard else None,
            "total_airtime_seconds": round(total_airtime, 1),
        }


    @router.get("/{file_id}")
    async def get_file(file_id: int, db: Session = Depends(get_db)):
        """Get file metadata and transcript."""
        recording = db.query(Recording).filter(Recording.id == file_id).first()
        if not recording:
            raise HTTPException(status_code=404, detail="Recording not found")

        callsign_tags = extract_callsign_tags(recording.transcript)
        ai_tags = parse_ai_tags(recording.ai_tags)

        # Repeater info
        repeater_info = None
        if recording.repeater_id:
            rep = db.query(Repeater).filter(Repeater.id == recording.repeater_id).first()
            if rep:
                repeater_info = {
                    "id": rep.id,
                    "callsign": rep.callsign,
                    "location": rep.location,
                    "county": rep.county,
                    "state": rep.state,
                    "frequency_hz": rep.frequency_hz,
                    "input_hz": rep.input_hz,
                    "pl_tone": rep.pl_tone,
                    "digital_modes": [m.strip() for m in rep.digital_modes.split(",")] if rep.digital_modes else [],
                    "linked_nodes": rep.linked_nodes,
                    "use": rep.use,
                }

        # Operator info for callsigns heard in transcript
        operators = []
        for cs in callsign_tags[:5]:
            info = db.query(CallsignInfo).filter(CallsignInfo.callsign == cs).first()
            if info:
                operators.append({
                    "callsign": info.callsign,
                    "name": info.name,
                    "qth_city": info.qth_city,
                    "qth_state": info.qth_state,
                    "license_class": info.license_class,
                    "grid": info.grid,
                })

        return {
            "id": recording.id,
            "filename": recording.filename,
            "mode": recording.mode,
            "frequency_hz": recording.frequency_hz,
            "timestamp": recording.timestamp.isoformat() if recording.timestamp else None,
            "duration_seconds": recording.duration_seconds,
            "transcript": recording.transcript,
            "frequency_label": recording.frequency_label,
            "callsign_tags": callsign_tags,
            "ai_tags": ai_tags,
            "tags": _all_tags(callsign_tags, ai_tags),
            "signal_db": recording.signal_db,
            "has_waveform": recording.waveform_cached is not None,
            "has_spectrogram": recording.spectrogram_cached is not None,
            "repeater": repeater_info,
            "operators": operators,
        }


    @router.get("/{file_id}/neighbors")
    async def get_file_neighbors(file_id: int, db: Session = Depends(get_db)):
        """Get previous and next recording IDs by timestamp."""
        recording = db.query(Recording).filter(Recording.id == file_id).first()
        if not recording:
            raise HTTPException(status_code=404, detail="Recording not found")
        ts = recording.timestamp
        if ts:
            prev_rec = (
                db.query(Recording.id)
                .filter(Recording.timestamp < ts)
                .order_by(desc(Recording.timestamp))
                .first()
            )
            next_rec = (
                db.query(Recording.id)
                .filter(Recording.timestamp > ts)
                .order_by(Recording.timestamp)
                .first()
            )
        else:
            prev_rec = (
                db.query(Recording.id)
                .filter(Recording.id < file_id)
                .order_by(desc(Recording.id))
                .first()
            )
            next_rec = (
                db.query(Recording.id)
                .filter(Recording.id > file_id)
                .order_by(Recording.id)
                .first()
            )
        return {
            "prev_id": prev_rec[0] if prev_rec else None,
            "next_id": next_rec[0] if next_rec else None,
        }


    @router.get("/{file_id}/related")
    async def get_related_recordings(file_id: int, db: Session = Depends(get_db)):
        """Get nearby recordings on the same frequency (±10 kHz, ±1 hour)."""
        recording = db.query(Recording).filter(Recording.id == file_id).first()
        if not recording:
            raise HTTPException(status_code=404, detail="Recording not found")
        items = []
        if recording.frequency_hz is not None and recording.timestamp is not None:
            ts_min = recording.timestamp - timedelta(hours=1)
            ts_max = recording.timestamp + timedelta(hours=1)
            freq_min = recording.frequency_hz - 10000
            freq_max = recording.frequency_hz + 10000
            rows = (
                db.query(Recording)
                .filter(
                    Recording.id != recording.id,
                    Recording.frequency_hz.between(freq_min, freq_max),
                    Recording.timestamp.between(ts_min, ts_max),
                )
                .order_by(desc(Recording.timestamp))
                .limit(10)
                .all()
            )
            for r in rows:
                cs_tags = extract_callsign_tags(r.transcript)
                ai_tags_list = parse_ai_tags(r.ai_tags)
                items.append({
                    "id": r.id,
                    "filename": r.filename,
                    "mode": r.mode,
                    "frequency_hz": r.frequency_hz,
                    "frequency_label": r.frequency_label,
                    "timestamp": r.timestamp.isoformat() if r.timestamp else None,
                    "duration_seconds": r.duration_seconds,
                    "has_transcript": bool((r.transcript or "").strip()),
                    "callsign_tags": cs_tags,
                    "ai_tags": ai_tags_list,
                    "tags": _all_tags(cs_tags, ai_tags_list),
                })
        return {"items": items, "count": len(items)}


    @router.patch("/{file_id}")
    async def update_recording(
        file_id: int, body: UpdateRecordingRequest, db: Session = Depends(get_db)
    ):
        """Update mutable fields on a recording (ai_tags and/or transcript)."""
        recording = db.query(Recording).filter(Recording.id == file_id).first()
        if not recording:
            raise HTTPException(status_code=404, detail="Recording not found")

        if body.ai_tags is not None:
            from ..services.tagging import dump_ai_tags
            recording.ai_tags = dump_ai_tags(body.ai_tags)

        if body.transcript is not None:
            new_transcript = body.transcript.strip() or None
            recording.transcript = new_transcript
            db.execute(
                sql_text("UPDATE recordings SET search_vector = NULL WHERE id = :id"),
                {"id": recording.id},
            )
            if new_transcript:
                db.execute(
                    sql_text(
                        "UPDATE recordings SET search_vector = to_tsvector('english', :t) WHERE id = :id"
                    ),
                    {"t": new_transcript, "id": recording.id},
                )

        db.commit()
        ai_tags = parse_ai_tags(recording.ai_tags)
        callsign_tags = extract_callsign_tags(recording.transcript)
        return {
            "id": recording.id,
            "ai_tags": ai_tags,
            "callsign_tags": callsign_tags,
            "tags": _all_tags(callsign_tags, ai_tags),
            "transcript": recording.transcript,
        }


    @router.post("/{file_id}/retag")
    async def retag_recording(file_id: int, db: Session = Depends(get_db)):
        """Clear AI tags so the indexer re-runs tagging on the next cycle."""
        recording = db.query(Recording).filter(Recording.id == file_id).first()
        if not recording:
            raise HTTPException(status_code=404, detail="Recording not found")
        recording.ai_tags = None
        db.commit()
        return {"status": "ok", "message": "AI tags cleared — will be regenerated on next indexer cycle"}


    @router.post("/{file_id}/retranscribe")
    async def retranscribe_recording(file_id: int, db: Session = Depends(get_db)):
        """Clear transcript and delete text file so Whisper re-transcribes on next cycle."""
        recording = db.query(Recording).filter(Recording.id == file_id).first()
        if not recording:
            raise HTTPException(status_code=404, detail="Recording not found")
        if not recording.audio_path:
            raise HTTPException(status_code=400, detail="No audio file — cannot re-transcribe")
        if recording.text_path and os.path.exists(recording.text_path):
            try:
                os.remove(recording.text_path)
            except OSError:
                pass
        recording.transcript = None
        recording.text_path = None
        recording.ai_tags = None
        db.execute(sql_text("UPDATE recordings SET search_vector = NULL WHERE id = :id"), {"id": recording.id})
        db.commit()
        return {"status": "ok", "message": "Transcript cleared — Whisper will re-transcribe on next cycle"}


    @router.get("/{file_id}/stream")
    async def stream_file(file_id: int, request: Request, db: Session = Depends(get_db)):
        """Stream audio file with Range request support."""
        recording = db.query(Recording).filter(Recording.id == file_id).first()
        if not recording:
            raise HTTPException(status_code=404, detail="Recording not found")

        audio_path = recording.audio_path
        if not os.path.exists(audio_path):
            raise HTTPException(status_code=404, detail="Audio file not found")

        file_size = os.path.getsize(audio_path)

        # Handle Range requests for seeking
        range_header = request.headers.get("Range")
        if range_header:
            try:
                range_spec = range_header.replace("bytes=", "")
                start, end = range_spec.split("-")
                start = int(start) if start else 0
                end = int(end) if end else file_size - 1
                end = min(end, file_size - 1)

                content_length = end - start + 1

                def iter_file():
                    with open(audio_path, "rb") as f:
                        f.seek(start)
                        remaining = content_length
                        while remaining > 0:
                            chunk_size = min(8192, remaining)
                            data = f.read(chunk_size)
                            if not data:
                                break
                            remaining -= len(data)
                            yield data

                return StreamingResponse(
                    iter_file(),
                    status_code=206,
                    media_type="audio/wav",
                    headers={
                        "Content-Range": f"bytes {start}-{end}/{file_size}",
                        "Content-Length": str(content_length),
                        "Accept-Ranges": "bytes",
                    },
                )
            except (ValueError, IndexError):
                pass

        # Full file response
        return FileResponse(
            audio_path,
            media_type="audio/wav",
            headers={"Accept-Ranges": "bytes"},
        )


    def _delete_recording_files(recording: Recording):
        """Remove audio, text, and cache files for a recording."""
        for path in [
            recording.audio_path,
            recording.text_path,
            recording.waveform_cached,
            recording.spectrogram_cached,
        ]:
            if path:
                try:
                    os.remove(path)
                except OSError:
                    pass


    @router.delete("/{file_id}")
    async def delete_file(file_id: int, db: Session = Depends(get_db)):
        """Delete a single recording and its files."""
        recording = db.query(Recording).filter(Recording.id == file_id).first()
        if not recording:
            raise HTTPException(status_code=404, detail="Recording not found")

        _delete_recording_files(recording)
        db.delete(recording)
        db.commit()
        return {"deleted": 1}


    @router.post("/bulk-delete")
    async def bulk_delete_files(body: BulkDeleteRequest, db: Session = Depends(get_db)):
        """Delete multiple recordings by ID."""
        recordings = db.query(Recording).filter(Recording.id.in_(body.ids)).all()
        count = 0
        for recording in recordings:
            _delete_recording_files(recording)
            db.delete(recording)
            count += 1
        db.commit()
        return {"deleted": count}


    @router.post("/bulk-delete-filtered")
    async def bulk_delete_filtered_files(
        body: BulkDeleteFilteredRequest,
        db: Session = Depends(get_db),
    ):
        """Delete all recordings matching the provided filter criteria."""
        _validate_mode(body.mode)
        _validate_duration_bounds(body.duration_min, body.duration_max)

        has_any_filter = any(
            [
                body.mode is not None,
                body.frequency_min is not None,
                body.frequency_max is not None,
                body.q is not None,
                body.callsign is not None,
                body.date_from is not None,
                body.date_to is not None,
                body.duration_min is not None,
                body.duration_max is not None,
                body.has_transcript is not None,
            ]
        )
        if not has_any_filter:
            raise HTTPException(
                status_code=400,
                detail="At least one filter is required for bulk-delete-filtered",
            )

        query = _apply_recording_filters(
            db.query(Recording),
            mode=body.mode,
            frequency_min=body.frequency_min,
            frequency_max=body.frequency_max,
            q=body.q,
            callsign=body.callsign,
            date_from=body.date_from,
            date_to=body.date_to,
            duration_min=body.duration_min,
            duration_max=body.duration_max,
            has_transcript=body.has_transcript,
        )
        recordings = query.all()
        matched = len(recordings)

        if body.dry_run:
            return {"matched": matched, "deleted": 0}

        for recording in recordings:
            _delete_recording_files(recording)
            db.delete(recording)
        db.commit()

        return {"matched": matched, "deleted": matched}


    @router.get("/tags")
    async def list_tags(limit: int = 200, db: Session = Depends(get_db)):
        """Return all distinct AI tags sorted by usage count for autocomplete."""
        rows = db.query(Recording.ai_tags).filter(Recording.ai_tags.isnot(None)).all()
        counts: dict = {}
        for (raw,) in rows:
            for tag in parse_ai_tags(raw):
                counts[tag] = counts.get(tag, 0) + 1
        sorted_tags = sorted(counts.items(), key=lambda x: x[1], reverse=True)[:limit]
        return {"tags": [{"tag": t, "count": c} for t, c in sorted_tags]}


    class UpdateNotesRequest(BaseModel):
        notes: Optional[str] = None


    @router.patch("/{recording_id}/notes")
    async def update_notes(
        recording_id: int,
        body: UpdateNotesRequest,
        db: Session = Depends(get_db),
    ):
        """Update operator notes on a recording."""
        rec = db.query(Recording).filter(Recording.id == recording_id).first()
        if not rec:
            raise HTTPException(status_code=404, detail="Recording not found")
        rec.notes = body.notes
        db.commit()
        return {"id": recording_id, "notes": rec.notes}


    @router.get("/export-zip")
    async def export_zip(
        mode: Optional[str] = None,
        frequency_min: Optional[float] = None,
        frequency_max: Optional[float] = None,
        date_from: Optional[datetime] = None,
        date_to: Optional[datetime] = None,
        tag: Optional[str] = None,
        limit: int = Query(200, ge=1, le=500),
        db: Session = Depends(get_db),
    ):
        """Stream a ZIP archive of matching audio recordings (WAV files only)."""
        query = db.query(Recording).filter(Recording.audio_path.isnot(None))
        if mode:
            query = query.filter(Recording.mode == mode)
        if frequency_min is not None:
            query = query.filter(Recording.frequency_hz >= frequency_min)
        if frequency_max is not None:
            query = query.filter(Recording.frequency_hz <= frequency_max)
        if date_from:
            query = query.filter(Recording.timestamp >= date_from)
        if date_to:
            query = query.filter(Recording.timestamp <= date_to)
        if tag:
            query = query.filter(Recording.ai_tags.ilike(f'%"{tag}"%'))
        recordings = query.order_by(Recording.timestamp.desc()).limit(limit).all()

        def generate_zip():
            buf = io.BytesIO()
            with zipfile.ZipFile(buf, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
                for rec in recordings:
                    if rec.audio_path and os.path.exists(rec.audio_path):
                        arcname = os.path.basename(rec.audio_path)
                        zf.write(rec.audio_path, arcname=arcname)
            buf.seek(0)
            yield buf.read()

        count = len(recordings)
        return StreamingResponse(
            generate_zip(),
            media_type="application/zip",
            headers={
                "Content-Disposition": f'attachment; filename="sdr-recordings-{count}.zip"',
                "X-Recording-Count": str(count),
            },
        )


    # ── Frequency Bookmarks ──────────────────────────────────────────────────────

    class BookmarkCreate(BaseModel):
        frequency_hz: float
        bandwidth_hz: float = 5000.0
        label: str
        notes: Optional[str] = None
        alert_on_activity: bool = False


    class BookmarkUpdate(BaseModel):
        label: Optional[str] = None
        bandwidth_hz: Optional[float] = None
        notes: Optional[str] = None
        alert_on_activity: Optional[bool] = None


    def _bm_row(bm) -> dict:
        return {
            "id": bm.id,
            "frequency_hz": bm.frequency_hz,
            "bandwidth_hz": bm.bandwidth_hz,
            "label": bm.label,
            "notes": bm.notes,
            "alert_on_activity": bm.alert_on_activity,
            "created_at": bm.created_at.isoformat() if bm.created_at else None,
        }


    @router.get("/bookmarks")
    async def list_bookmarks(db: Session = Depends(get_db)):
        from ..models import FrequencyBookmark
        rows = db.query(FrequencyBookmark).order_by(FrequencyBookmark.frequency_hz).all()
        return {"items": [_bm_row(r) for r in rows]}


    @router.post("/bookmarks", status_code=201)
    async def create_bookmark(body: BookmarkCreate, db: Session = Depends(get_db)):
        from ..models import FrequencyBookmark
        if not body.label.strip():
            raise HTTPException(status_code=422, detail="label cannot be empty")
        bm = FrequencyBookmark(
            frequency_hz=body.frequency_hz,
            bandwidth_hz=body.bandwidth_hz,
            label=body.label.strip(),
            notes=body.notes,
            alert_on_activity=body.alert_on_activity,
        )
        db.add(bm)
        db.commit()
        db.refresh(bm)
        return _bm_row(bm)


    @router.patch("/bookmarks/{bookmark_id}")
    async def update_bookmark(
        bookmark_id: int, body: BookmarkUpdate, db: Session = Depends(get_db)
    ):
        from ..models import FrequencyBookmark
        bm = db.query(FrequencyBookmark).filter(FrequencyBookmark.id == bookmark_id).first()
        if not bm:
            raise HTTPException(status_code=404, detail="Bookmark not found")
        if body.label is not None:
            bm.label = body.label.strip()
        if body.bandwidth_hz is not None:
            bm.bandwidth_hz = body.bandwidth_hz
        if body.notes is not None:
            bm.notes = body.notes
        if body.alert_on_activity is not None:
            bm.alert_on_activity = body.alert_on_activity
        db.commit()
        return _bm_row(bm)


    @router.delete("/bookmarks/{bookmark_id}")
    async def delete_bookmark(bookmark_id: int, db: Session = Depends(get_db)):
        from ..models import FrequencyBookmark
        bm = db.query(FrequencyBookmark).filter(FrequencyBookmark.id == bookmark_id).first()
        if not bm:
            raise HTTPException(status_code=404, detail="Bookmark not found")
        db.delete(bm)
        db.commit()
        return {"deleted": bookmark_id}
  search.py: |
    import csv
    import io
    from typing import Optional, List

    import requests
    from fastapi import APIRouter, Depends, HTTPException, Query
    from fastapi.responses import StreamingResponse
    from sqlalchemy import func, text
    from sqlalchemy.orm import Session

    from ..database import get_db
    from ..models import Recording
    from ..services.tagging import extract_callsign_tags, normalize_callsign, parse_ai_tags

    router = APIRouter()


    @router.get("/text")
    async def search_text(
        q: str = Query(..., min_length=1),
        mode: Optional[str] = Query(None, pattern="^(cw|voice|aprs)$"),
        frequency_min: Optional[float] = None,
        frequency_max: Optional[float] = None,
        callsign: Optional[str] = Query(None, min_length=1, max_length=20),
        page: int = Query(1, ge=1),
        limit: int = Query(50, ge=1, le=200),
        format: Optional[str] = Query(None),
        db: Session = Depends(get_db),
    ):
        """Full-text search on transcripts."""
        search_query = func.plainto_tsquery("english", q)

        query = db.query(
            Recording,
            func.ts_rank(Recording.search_vector, search_query).label("rank"),
            func.ts_headline(
                "english",
                Recording.transcript,
                search_query,
                "StartSel=<mark>, StopSel=</mark>, MaxWords=50, MinWords=20",
            ).label("headline"),
        ).filter(Recording.search_vector.op("@@")(search_query))

        if mode:
            query = query.filter(Recording.mode == mode)
        if frequency_min is not None:
            query = query.filter(Recording.frequency_hz >= frequency_min)
        if frequency_max is not None:
            query = query.filter(Recording.frequency_hz <= frequency_max)

        if callsign:
            normalized_callsign = normalize_callsign(callsign)
            if normalized_callsign:
                normalized_transcript = func.regexp_replace(
                    func.upper(func.coalesce(Recording.transcript, "")),
                    "[^A-Z0-9]+",
                    "",
                    "g",
                )
                query = query.filter(normalized_transcript.ilike(f"%{normalized_callsign}%"))

        total = query.count()

        if format == "csv":
            csv_rows = query.order_by(text("rank DESC")).limit(5000).all()
            buf = io.StringIO()
            writer = csv.writer(buf)
            writer.writerow(["id", "filename", "mode", "frequency_hz", "frequency_label", "timestamp", "rank", "tags", "headline"])
            for r in csv_rows:
                cs_tags = extract_callsign_tags(r.Recording.transcript)
                ai_tags = parse_ai_tags(r.Recording.ai_tags)
                all_tags = ";".join(list(dict.fromkeys(cs_tags + ai_tags)))
                writer.writerow([
                    r.Recording.id,
                    r.Recording.filename,
                    r.Recording.mode or "",
                    r.Recording.frequency_hz or "",
                    r.Recording.frequency_label or "",
                    r.Recording.timestamp.isoformat() if r.Recording.timestamp else "",
                    f"{float(r.rank):.4f}",
                    all_tags,
                    (r.headline or "").replace("<mark>", "").replace("</mark>", ""),
                ])
            buf.seek(0)
            safe_q = q[:40].replace("/", "_").replace(" ", "_")
            return StreamingResponse(
                iter([buf.getvalue()]),
                media_type="text/csv",
                headers={"Content-Disposition": f'attachment; filename="search_{safe_q}.csv"'},
            )

        results = query.order_by(text("rank DESC")).offset((page - 1) * limit).limit(limit).all()

        return {
            "query": q,
            "total": total,
            "page": page,
            "limit": limit,
            "items": [
                {
                    "id": r.Recording.id,
                    "filename": r.Recording.filename,
                    "mode": r.Recording.mode,
                    "frequency_hz": r.Recording.frequency_hz,
                    "frequency_label": r.Recording.frequency_label,
                    "timestamp": r.Recording.timestamp.isoformat() if r.Recording.timestamp else None,
                    "headline": r.headline,
                    "rank": float(r.rank),
                    "callsign_tags": (callsign_tags := extract_callsign_tags(r.Recording.transcript)),
                    "ai_tags": (ai_tags := parse_ai_tags(r.Recording.ai_tags)),
                    "tags": list(dict.fromkeys(callsign_tags + ai_tags)),
                }
                for r in results
            ],
        }


    @router.get("/callsign")
    def search_callsign(
        q: str = Query(..., min_length=1, max_length=100),
    ):
        """Look up an amateur radio callsign or operator name via FCC ULS."""
        try:
            resp = requests.get(
                "https://data.fcc.gov/api/license-view/basicSearch/getLicenses",
                params={"searchValue": q.strip(), "service": "HA", "format": "json", "rows": 25},
                timeout=10.0,
            )
            resp.raise_for_status()
            data = resp.json()
        except requests.RequestException as e:
            raise HTTPException(status_code=502, detail=f"FCC ULS lookup failed: {e}")

        raw = data.get("Licenses", {}).get("License", [])
        if isinstance(raw, dict):
            raw = [raw]

        results = []
        for lic in raw:
            callsign = (lic.get("callsign") or "").strip().upper()
            if not callsign:
                continue
            lic_name = (lic.get("licName") or "").strip()
            # FCC format: "SMITH, JOHN A" → "John A Smith"
            if "," in lic_name:
                last, _, first = lic_name.partition(",")
                name = f"{first.strip().title()} {last.strip().title()}"
            else:
                name = lic_name.title()
            results.append({
                "callsign": callsign,
                "name": name or None,
                "status": lic.get("statusDesc", ""),
                "expired_date": lic.get("expiredDate") or None,
            })

        return {"query": q, "results": results, "total": len(results)}


    @router.get("/similar/{recording_id}")
    async def search_similar(
        recording_id: int,
        limit: int = Query(10, ge=1, le=50),
        db: Session = Depends(get_db),
    ):
        """Find recordings with transcripts similar to the given recording."""
        rec = db.query(Recording).filter(Recording.id == recording_id).first()
        if not rec:
            raise HTTPException(status_code=404, detail="Recording not found")
        if not rec.transcript or not rec.search_vector:
            return {"items": [], "total": 0}
        search_query = func.plainto_tsquery("english", rec.transcript[:500])
        results = (
            db.query(
                Recording,
                func.ts_rank(Recording.search_vector, search_query).label("rank"),
            )
            .filter(
                Recording.search_vector.op("@@")(search_query),
                Recording.id != recording_id,
            )
            .order_by(text("rank DESC"))
            .limit(limit)
            .all()
        )
        return {
            "items": [
                {
                    "id": r.Recording.id,
                    "filename": r.Recording.filename,
                    "mode": r.Recording.mode,
                    "frequency_hz": r.Recording.frequency_hz,
                    "frequency_label": r.Recording.frequency_label,
                    "timestamp": r.Recording.timestamp.isoformat() if r.Recording.timestamp else None,
                    "transcript": (r.Recording.transcript or "")[:300],
                    "rank": float(r.rank),
                    "ai_tags": parse_ai_tags(r.Recording.ai_tags),
                }
                for r in results
            ],
            "total": len(results),
        }
  tagging.py: |
    import json
    import os
    import re
    from typing import List, Optional


    CALLSIGN_PATTERN = re.compile(r"\b(?:[AKNW][A-Z]?\d[A-Z]{1,3})\b", re.IGNORECASE)
    NO_SPEECH_PATTERN = re.compile(
        r"^\s*(?:"
        r"\[?\s*no speech detected\s*\]?"
        r"|\[?\s*recording too long for auto-transcribe\s*\]?"
        r"|[^\w\s]+"
        r"|thanks?\s+(?:for\s+)?(?:watching|listening)\.?"
        r"|(?:thank\s+you|bye|goodbye|see\s+you)\.?"
        r"|\[(?:music|applause|laughter|silence|noise|inaudible)[^\]]*\]"
        r")\s*$",
        re.IGNORECASE,
    )

    PHONETIC_MAP = {
        "ALFA": "A", "ALPHA": "A", "BRAVO": "B", "CHARLIE": "C", "DELTA": "D",
        "ECHO": "E", "FOXTROT": "F", "GOLF": "G", "HOTEL": "H", "INDIA": "I",
        "JULIETT": "J", "JULIET": "J", "KILO": "K", "LIMA": "L", "MIKE": "M",
        "NOVEMBER": "N", "OSCAR": "O", "PAPA": "P", "QUEBEC": "Q", "ROMEO": "R",
        "SIERRA": "S", "TANGO": "T", "UNIFORM": "U", "VICTOR": "V", "WHISKEY": "W",
        "XRAY": "X", "X-RAY": "X", "YANKEE": "Y", "ZULU": "Z",
        "ZERO": "0", "OH": "0", "ONE": "1", "TWO": "2", "TOO": "2",
        "THREE": "3", "TREE": "3", "FOUR": "4", "FIVE": "5", "SIX": "6",
        "SEVEN": "7", "EIGHT": "8", "NINE": "9", "NINER": "9",
    }


    def normalize_callsign(value: str) -> str:
        return re.sub(r"[^A-Z0-9]", "", value.upper())


    def callsign_hints() -> List[str]:
        raw = os.getenv("CALLSIGN_HINTS", "w3rdw")
        hints: List[str] = []
        for token in raw.split(","):
            normalized = normalize_callsign(token.strip())
            if normalized:
                hints.append(normalized)
        return hints


    def phonetic_compact(text: str) -> str:
        tokens = re.findall(r"[A-Z0-9-]+", text.upper())
        compact: List[str] = []
        for token in tokens:
            mapped = PHONETIC_MAP.get(token)
            if mapped:
                compact.append(mapped)
                continue
            if len(token) == 1 and token.isalnum():
                compact.append(token)
                continue
            if token.isdigit():
                compact.append(token)
        return "".join(compact)


    def extract_callsign_tags(transcript: Optional[str]) -> List[str]:
        if not transcript:
            return []
        tags: List[str] = []
        seen = set()
        for match in CALLSIGN_PATTERN.finditer(transcript):
            tag = normalize_callsign(match.group(0))
            if tag and tag not in seen:
                seen.add(tag)
                tags.append(tag)
        normalized_text = normalize_callsign(transcript)
        phonetic_text = phonetic_compact(transcript)
        for hint in callsign_hints():
            if (hint in normalized_text or hint in phonetic_text) and hint not in seen:
                seen.add(hint)
                tags.append(hint)
        return tags


    def is_no_speech_transcript(transcript: Optional[str]) -> bool:
        if not transcript:
            return False
        return NO_SPEECH_PATTERN.match(transcript) is not None


    def parse_ai_tags(raw: Optional[str]) -> List[str]:
        if not raw:
            return []
        try:
            value = json.loads(raw)
        except json.JSONDecodeError:
            return []
        if not isinstance(value, list):
            return []
        tags: List[str] = []
        seen = set()
        for item in value:
            if not isinstance(item, str):
                continue
            cleaned = item.strip()
            if cleaned and cleaned not in seen:
                seen.add(cleaned)
                tags.append(cleaned)
        return tags


    def dump_ai_tags(tags: List[str]) -> Optional[str]:
        cleaned: List[str] = []
        seen = set()
        for tag in tags:
            normalized = tag.strip()
            if normalized and normalized not in seen:
                seen.add(normalized)
                cleaned.append(normalized)
        if not cleaned:
            return None
        return json.dumps(cleaned)
  known_freqs.py: |
    """
    Static lookup table of well-known frequencies.

    Frequencies are stored in Hz with a match tolerance. The first match wins,
    so list more specific entries (narrow-band) before broader band ranges.
    Edit this configmap to add or adjust entries without rebuilding the image.
    """

    from typing import Optional


    # (center_hz, tolerance_hz, label)
    _KNOWN: list[tuple[float, float, str]] = [
        # ── NOAA Weather Radio ────────────────────────────────────────────────
        (162_400_000, 3_000, "NOAA WX-1"),
        (162_425_000, 3_000, "NOAA WX-2"),
        (162_450_000, 3_000, "NOAA WX-3"),
        (162_475_000, 3_000, "NOAA WX-4"),
        (162_500_000, 3_000, "NOAA WX-5"),
        (162_525_000, 3_000, "NOAA WX-6"),
        (162_550_000, 3_000, "NOAA WX-7"),

        # ── Amateur — 2m ──────────────────────────────────────────────────────
        (144_200_000, 3_000, "2m SSB Calling"),
        (144_390_000, 3_000, "APRS 2m"),
        (146_520_000, 5_000, "2m National Simplex Calling"),
        (146_580_000, 5_000, "2m FM Simplex"),
        (147_555_000, 5_000, "2m FM Simplex"),

        # ── Amateur — 70cm ────────────────────────────────────────────────────
        (432_100_000, 3_000, "70cm SSB Calling"),
        (433_920_000, 5_000, "70cm FM Simplex"),
        (446_000_000, 5_000, "70cm National Simplex Calling"),
        (446_500_000, 5_000, "70cm FM Simplex"),

        # ── Amateur — 1.25m ───────────────────────────────────────────────────
        (223_500_000, 5_000, "1.25m National Simplex Calling"),

        # ── ISS ───────────────────────────────────────────────────────────────
        (145_800_000, 5_000, "ISS Voice Downlink"),
        (437_550_000, 5_000, "ISS Packet"),
        (145_825_000, 3_000, "ISS APRS"),

        # ── Aviation ──────────────────────────────────────────────────────────
        (121_500_000, 5_000, "Aviation Distress (Guard)"),
        (122_750_000, 5_000, "Aviation Multicom"),
        (123_025_000, 5_000, "Aviation Unicom"),
        (123_450_000, 5_000, "Aviation Air-to-Air"),

        # ── Marine VHF ───────────────────────────────────────────────────────
        (156_800_000, 5_000, "Marine Ch 16 (Distress/Calling)"),
        (156_300_000, 5_000, "Marine Ch 6 (Safety)"),
        (157_050_000, 5_000, "Marine Ch 22A (USCG Working)"),

        # ── FRS/GMRS simplex ─────────────────────────────────────────────────
        (462_562_500, 5_000, "FRS/GMRS Ch 1"),
        (462_587_500, 5_000, "FRS/GMRS Ch 2"),
        (462_612_500, 5_000, "FRS/GMRS Ch 3"),
        (462_637_500, 5_000, "FRS/GMRS Ch 4"),
        (462_662_500, 5_000, "FRS/GMRS Ch 5"),
        (462_687_500, 5_000, "FRS/GMRS Ch 6"),
        (462_712_500, 5_000, "FRS/GMRS Ch 7"),
        (467_562_500, 5_000, "FRS Ch 8"),
        (467_587_500, 5_000, "FRS Ch 9"),
        (467_612_500, 5_000, "FRS Ch 10"),
        (467_637_500, 5_000, "FRS Ch 11"),
        (467_662_500, 5_000, "FRS Ch 12"),
        (467_687_500, 5_000, "FRS Ch 13"),
        (467_712_500, 5_000, "FRS Ch 14"),
        (462_550_000, 5_000, "GMRS Ch 15 (Calling)"),
        (462_575_000, 5_000, "GMRS Ch 16"),
        (462_600_000, 5_000, "GMRS Ch 17"),
        (462_625_000, 5_000, "GMRS Ch 18"),
        (462_650_000, 5_000, "GMRS Ch 19"),
        (462_675_000, 5_000, "GMRS Ch 20"),
        (462_700_000, 5_000, "GMRS Ch 21"),
        (462_725_000, 5_000, "GMRS Ch 22"),

        # ── MURS ─────────────────────────────────────────────────────────────
        (151_820_000, 5_000, "MURS Ch 1"),
        (151_880_000, 5_000, "MURS Ch 2"),
        (151_940_000, 5_000, "MURS Ch 3"),
        (154_570_000, 5_000, "MURS Ch 4"),
        (154_600_000, 5_000, "MURS Ch 5"),
    ]


    def lookup_known_freq(frequency_hz: float) -> Optional[str]:
        """Return a human label for a known frequency, or None if unrecognized."""
        for center, tolerance, label in _KNOWN:
            if abs(frequency_hz - center) <= tolerance:
                return label
        return None
  repeaters.py: |
    from typing import Optional

    from fastapi import APIRouter, Depends, Query
    from sqlalchemy import asc
    from sqlalchemy.orm import Session

    from ..database import get_db
    from ..models import Repeater

    router = APIRouter()


    @router.get("/station")
    async def get_station_center():
        """Return the configured station coordinates (used as map center)."""
        from ..config import settings
        return {
            "latitude": settings.repeaterbook_latitude,
            "longitude": settings.repeaterbook_longitude,
        }


    @router.get("")
    async def list_repeaters(
        state: Optional[str] = Query(None, min_length=2, max_length=50),
        callsign: Optional[str] = Query(None, min_length=1, max_length=20),
        frequency_min: Optional[float] = None,
        frequency_max: Optional[float] = None,
        digital_only: bool = False,
        digital_mode: Optional[str] = Query(None, min_length=1, max_length=30),
        page: int = Query(1, ge=1),
        limit: int = Query(100, ge=1, le=2000),
        db: Session = Depends(get_db),
    ):
        """Browse known repeaters from the local RepeaterBook cache."""
        query = db.query(Repeater)

        if state:
            query = query.filter(Repeater.state.ilike(f"%{state}%"))
        if callsign:
            query = query.filter(Repeater.callsign.ilike(f"%{callsign.upper()}%"))
        if frequency_min is not None:
            query = query.filter(Repeater.frequency_hz >= frequency_min)
        if frequency_max is not None:
            query = query.filter(Repeater.frequency_hz <= frequency_max)
        if digital_only or digital_mode:
            query = query.filter(
                Repeater.digital_modes.isnot(None),
                Repeater.digital_modes != "",
            )
        if digital_mode:
            query = query.filter(Repeater.digital_modes.ilike(f"%{digital_mode}%"))

        total = query.count()
        repeaters = (
            query.order_by(asc(Repeater.frequency_hz))
            .offset((page - 1) * limit)
            .limit(limit)
            .all()
        )

        return {
            "total": total,
            "page": page,
            "limit": limit,
            "items": [
                {
                    "id": r.id,
                    "callsign": r.callsign,
                    "frequency_hz": r.frequency_hz,
                    "input_hz": r.input_hz,
                    "pl_tone": r.pl_tone,
                    "location": r.location,
                    "county": r.county,
                    "state": r.state,
                    "latitude": r.latitude,
                    "longitude": r.longitude,
                    "use": r.use,
                    "digital_modes": [m.strip() for m in r.digital_modes.split(",")] if r.digital_modes else [],
                    "linked_nodes": r.linked_nodes,
                    "last_synced": r.last_synced.isoformat() if r.last_synced else None,
                }
                for r in repeaters
            ],
        }
  main.py: |
    import asyncio
    from contextlib import asynccontextmanager

    from fastapi import FastAPI
    from fastapi.middleware.cors import CORSMiddleware
    from prometheus_fastapi_instrumentator import Instrumentator

    from .database import engine, Base
    from .routers import admin, aprs, files, repeaters, search, stats, waveform
    from .services.indexer import run_indexer
    from .services.repeater import run_repeater_sync


    @asynccontextmanager
    async def lifespan(app: FastAPI):
        Base.metadata.create_all(bind=engine)
        indexer_task = asyncio.create_task(run_indexer())
        repeater_task = asyncio.create_task(run_repeater_sync())
        yield
        for task in (indexer_task, repeater_task):
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass


    app = FastAPI(
        title="SDR Viewer API",
        description="API for browsing and streaming SDR recordings",
        version="0.1.0",
        lifespan=lifespan,
    )

    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    app.include_router(files.router, prefix="/api/v1/files", tags=["files"])
    app.include_router(search.router, prefix="/api/v1/search", tags=["search"])
    app.include_router(waveform.router, prefix="/api/v1/waveform", tags=["waveform"])
    app.include_router(repeaters.router, prefix="/api/v1/repeaters", tags=["repeaters"])
    app.include_router(aprs.router, prefix="/api/v1/aprs", tags=["aprs"])
    app.include_router(stats.router, prefix="/api/v1/stats", tags=["stats"])
    app.include_router(admin.router, prefix="/api/v1/admin", tags=["admin"])

    Instrumentator().instrument(app).expose(app, endpoint="/metrics", include_in_schema=False)


    @app.get("/api/v1/health")
    async def health():
        return {"status": "ok"}

  aprs.py: |
    import re
    from datetime import datetime, timedelta
    from typing import Optional

    from fastapi import APIRouter, Depends, Query
    from sqlalchemy import desc
    from sqlalchemy.orm import Session

    from ..database import get_db
    from ..models import Recording

    router = APIRouter()

    # Uncompressed APRS position: !DDMM.mmN/DDDMM.mmW  (symbol table char between)
    # Optional (?:\d{6}[z/h])? handles @DDHHMM[z/h] timestamp prefix in @ packets
    _POS_RE = re.compile(
        r"[!=@/\\](?:\d{6}[z/h])?(\d{2})(\d{2}\.\d+)([NS])(.)(\d{3})(\d{2}\.\d+)([EW])"
    )
    _SPEED_COURSE_RE = re.compile(r"(\d{3})/(\d{3})")
    _ALT_RE = re.compile(r"A=(\d{6})")
    # APRS weather field pattern: cDDD sSS gGGG tTTT [rRRR] [pPPP] [hHH] [bBBBBB]
    _WEATHER_RE = re.compile(
        r"c(\d{3}|\.\.\.)s(\d{3}|\.\.\.)g(\d{3}|\.\.\.)t(-?\d{3}|\.\.\.)(?:r(\d{3}|\.{3}))?(?:p(\d{3}|\.{3}))?(?:h(\d{2}|\.{2}))?(?:b(\d{5}|\.{5}))?"
    )


    def _parse_weather(payload: str):
        m = _WEATHER_RE.search(payload)
        if not m:
            return None
        def _v(s):
            if s is None or "." in s:
                return None
            return int(s)
        wd = _v(m.group(1))
        ws = _v(m.group(2))
        wg = _v(m.group(3))
        temp = _v(m.group(4))
        if ws is None and temp is None:
            return None  # not a real weather packet
        r1 = _v(m.group(5))
        r24 = _v(m.group(6))
        hum = _v(m.group(7))
        baro = _v(m.group(8))
        return {
            "wind_dir_deg": wd,
            "wind_speed_mph": ws,
            "wind_gust_mph": wg,
            "temp_f": temp,
            "rain_1h_in": round(r1 * 0.01, 2) if r1 is not None else None,
            "rain_24h_in": round(r24 * 0.01, 2) if r24 is not None else None,
            "humidity_pct": hum,
            "pressure_mbar": round(baro * 0.1, 1) if baro is not None else None,
        }


    def _parse_position(payload: str):
        m = _POS_RE.search(payload)
        if not m:
            return None
        lat_d, lat_m, lat_h, _, lon_d, lon_m, lon_h = m.groups()
        lat = float(lat_d) + float(lat_m) / 60
        if lat_h == "S":
            lat = -lat
        lon = float(lon_d) + float(lon_m) / 60
        if lon_h == "W":
            lon = -lon
        return round(lat, 6), round(lon, 6)


    def _parse_comment(payload: str) -> str:
        s = re.sub(r"^[!=@/\\]\d{4}\.\d+[NS].\d{5}\.\d+[EW].", "", payload)
        s = re.sub(r"^\d{3}/\d{3}", "", s)
        s = re.sub(r"/?A=\d+", "", s)
        return s.strip()


    def _parse_packet(line: str):
        if ">" not in line or ":" not in line:
            return None
        try:
            callsign = line.split(">")[0].strip()
            colon_idx = line.index(":")
            header = line[:colon_idx]
            payload = line[colon_idx + 1:]
            path_parts = header.split(",")
            path = ",".join(path_parts[1:]) if len(path_parts) > 1 else ""
            pos = _parse_position(payload)
            sc = _SPEED_COURSE_RE.search(payload[1:20] if len(payload) > 1 else "")
            speed_kt = int(sc.group(2)) if sc else None
            course = int(sc.group(1)) if sc else None
            alt_m = _ALT_RE.search(payload)
            altitude_ft = int(alt_m.group(1)) if alt_m else None
            comment = _parse_comment(payload)
            # Detect WX: data-type '_' (no-position) OR '_' symbol char after position
            is_weather = len(payload) > 0 and payload[0] == "_"
            if not is_weather:
                _pm = _POS_RE.search(payload)
                if _pm and _pm.end() < len(payload) and payload[_pm.end()] == "_":
                    is_weather = True
            weather = _parse_weather(payload) if is_weather else None
            return {
                "callsign": callsign,
                "path": path,
                "latitude": pos[0] if pos else None,
                "longitude": pos[1] if pos else None,
                "speed_kt": speed_kt,
                "course": course,
                "altitude_ft": altitude_ft,
                "comment": comment,
                "packet": line.strip(),
                "is_weather": is_weather,
                "weather": weather,
            }
        except Exception:
            return None


    @router.get("/stations")
    def get_aprs_stations(
        hours: int = Query(24, ge=1, le=168),
        db: Session = Depends(get_db),
    ):
        since = datetime.utcnow() - timedelta(hours=hours)
        rows = (
            db.query(Recording)
            .filter(
                Recording.mode == "aprs",
                Recording.transcript.isnot(None),
                Recording.timestamp >= since,
            )
            .order_by(desc(Recording.timestamp))
            .limit(2000)
            .all()
        )
        stations: dict = {}
        for rec in rows:
            for line in (rec.transcript or "").splitlines():
                p = _parse_packet(line)
                if not p:
                    continue
                cs = p["callsign"]
                if cs not in stations:
                    stations[cs] = {
                        **p,
                        "last_heard": rec.timestamp.isoformat() if rec.timestamp else None,
                        "frequency_hz": rec.frequency_hz,
                    }
                elif p["latitude"] is not None and stations[cs]["latitude"] is None:
                    stations[cs].update({
                        **p,
                        "last_heard": rec.timestamp.isoformat() if rec.timestamp else None,
                    })
        return {"stations": list(stations.values()), "hours": hours}


    @router.get("/tracks")
    def get_aprs_tracks(
        hours: int = Query(24, ge=1, le=168),
        db: Session = Depends(get_db),
    ):
        """Return per-callsign position tracks for drawing on the map."""
        since = datetime.utcnow() - timedelta(hours=hours)
        rows = (
            db.query(Recording)
            .filter(
                Recording.mode == "aprs",
                Recording.transcript.isnot(None),
                Recording.timestamp >= since,
            )
            .order_by(Recording.timestamp)
            .limit(5000)
            .all()
        )
        tracks: dict = {}
        for rec in rows:
            for line in (rec.transcript or "").splitlines():
                p = _parse_packet(line)
                if not p or p["latitude"] is None or p["longitude"] is None:
                    continue
                cs = p["callsign"]
                if cs not in tracks:
                    tracks[cs] = []
                tracks[cs].append({
                    "lat": p["latitude"],
                    "lon": p["longitude"],
                    "timestamp": rec.timestamp.isoformat() if rec.timestamp else None,
                })
        return {
            "tracks": [
                {"callsign": cs, "positions": positions}
                for cs, positions in tracks.items()
                if len(positions) >= 2
            ],
            "hours": hours,
        }


    @router.get("/packets")
    def get_aprs_packets(
        callsign: Optional[str] = None,
        hours: int = Query(24, ge=1, le=168),
        page: int = Query(1, ge=1),
        limit: int = Query(50, ge=1, le=200),
        db: Session = Depends(get_db),
    ):
        since = datetime.utcnow() - timedelta(hours=hours)
        q = db.query(Recording).filter(
            Recording.mode == "aprs",
            Recording.timestamp >= since,
        )
        if callsign:
            q = q.filter(Recording.transcript.ilike(f"%{callsign.upper()}%"))
        total = q.count()
        rows = (
            q.order_by(desc(Recording.timestamp))
            .offset((page - 1) * limit)
            .limit(limit)
            .all()
        )
        packets = []
        for rec in rows:
            for line in (rec.transcript or "").splitlines():
                p = _parse_packet(line)
                if p:
                    packets.append({
                        **p,
                        "id": rec.id,
                        "timestamp": rec.timestamp.isoformat() if rec.timestamp else None,
                        "frequency_hz": rec.frequency_hz,
                    })
        return {"packets": packets, "total": total, "page": page, "limit": limit}


    @router.get("/export")
    def export_aprs(
        format: str = Query("geojson", regex="^(geojson|csv)$"),
        hours: int = Query(24, ge=1, le=168),
        db: Session = Depends(get_db),
    ):
        """Export all APRS station positions as GeoJSON or CSV."""
        import csv as _csv
        import io as _io
        from fastapi.responses import StreamingResponse

        since = datetime.utcnow() - timedelta(hours=hours)
        rows = (
            db.query(Recording)
            .filter(
                Recording.mode == "aprs",
                Recording.transcript.isnot(None),
                Recording.timestamp >= since,
            )
            .order_by(desc(Recording.timestamp))
            .limit(5000)
            .all()
        )

        # Collect unique latest position per callsign
        stations: dict = {}
        for rec in rows:
            for line in (rec.transcript or "").splitlines():
                p = _parse_packet(line)
                if not p:
                    continue
                cs = p["callsign"]
                if cs not in stations:
                    stations[cs] = {
                        **p,
                        "last_heard": rec.timestamp.isoformat() if rec.timestamp else None,
                        "frequency_hz": rec.frequency_hz,
                    }

        if format == "geojson":
            features = []
            for cs, s in stations.items():
                if s["latitude"] is None or s["longitude"] is None:
                    continue
                features.append({
                    "type": "Feature",
                    "geometry": {"type": "Point", "coordinates": [s["longitude"], s["latitude"]]},
                    "properties": {
                        "callsign": cs,
                        "last_heard": s.get("last_heard"),
                        "comment": s.get("comment"),
                        "speed_kt": s.get("speed_kt"),
                        "altitude_ft": s.get("altitude_ft"),
                        "frequency_hz": s.get("frequency_hz"),
                    },
                })
            geojson = {"type": "FeatureCollection", "features": features}
            import json as _json
            return StreamingResponse(
                _io.BytesIO(_json.dumps(geojson, indent=2).encode()),
                media_type="application/geo+json",
                headers={"Content-Disposition": f'attachment; filename="aprs-{hours}h.geojson"'},
            )

        # CSV
        buf = _io.StringIO()
        writer = _csv.writer(buf)
        writer.writerow(["callsign", "latitude", "longitude", "last_heard", "comment",
                          "speed_kt", "altitude_ft", "frequency_hz"])
        for cs, s in stations.items():
            writer.writerow([
                cs,
                s.get("latitude", ""),
                s.get("longitude", ""),
                s.get("last_heard", ""),
                s.get("comment", ""),
                s.get("speed_kt", ""),
                s.get("altitude_ft", ""),
                s.get("frequency_hz", ""),
            ])
        return StreamingResponse(
            _io.BytesIO(buf.getvalue().encode()),
            media_type="text/csv",
            headers={"Content-Disposition": f'attachment; filename="aprs-{hours}h.csv"'},
        )


    @router.get("/voice-callsigns")
    async def voice_callsigns(
        hours: int = Query(72, ge=1, le=720),
        db: Session = Depends(get_db),
    ):
        """
        Return callsigns heard in voice recordings with their FCC-registered coordinates.
        Used to overlay operator positions on the map alongside APRS stations.
        """
        from ..models import CallsignInfo
        from ..services.tagging import extract_callsign_tags, parse_ai_tags
        cutoff = datetime.utcnow() - timedelta(hours=hours)
        recs = (
            db.query(Recording)
            .filter(
                Recording.mode == "voice",
                Recording.timestamp >= cutoff,
                Recording.transcript.isnot(None),
            )
            .order_by(Recording.timestamp.desc())
            .limit(1000)
            .all()
        )
        # Collect unique callsigns with their lat/lon from callsign_cache
        callsign_latest: dict = {}
        for rec in recs:
            cs_tags = extract_callsign_tags(rec.transcript)
            ai_tags = parse_ai_tags(rec.ai_tags)
            all_cs = list(dict.fromkeys(cs_tags + ai_tags))
            for cs in all_cs:
                if cs not in callsign_latest:
                    callsign_latest[cs] = rec.timestamp
        stations = []
        for cs, last_heard in callsign_latest.items():
            info = db.query(CallsignInfo).filter(CallsignInfo.callsign == cs).first()
            if not info or info.latitude is None or info.longitude is None:
                continue
            stations.append({
                "callsign": cs,
                "name": info.name,
                "latitude": info.latitude,
                "longitude": info.longitude,
                "qth_city": info.qth_city,
                "qth_state": info.qth_state,
                "grid": info.grid,
                "last_heard": last_heard.isoformat() if last_heard else None,
            })
        return {"stations": stations, "total": len(stations)}

  indexer.py: |
    import asyncio
    import json
    import os
    import re
    import time as _time
    from datetime import datetime
    from pathlib import Path
    from urllib import error, request

    import numpy as np
    import librosa
    from sqlalchemy import text

    from ..config import settings
    from ..database import SessionLocal
    from ..models import Recording
    from .audio import compute_signal_db, generate_waveform_peaks, get_time_segments
    from .alerting import check_alerts
    from .hamdb import callsign_context_str, lookup_callsigns
    from .known_freqs import lookup_known_freq
    from .repeater import lookup_repeater, repeater_label, repeater_tags
    from .tagging import dump_ai_tags, extract_callsign_tags, is_no_speech_transcript
    from .metrics import (
        indexer_files_indexed, indexer_files_deleted, indexer_cycle_duration,
        indexer_last_run, indexer_ollama_calls, indexer_ollama_errors,
        aprs_packets_indexed, recordings_total, recordings_with_transcript,
        recordings_with_ai_tags, recordings_with_repeater,
        recordings_pending_transcript, recordings_pending_ai_tags,
        recordings_pending_freq_label, repeater_count, repeater_sync_age_seconds,
        sdr_hardware_last_seen_seconds,
    )


    CALLSIGN_TAG_PATTERN = re.compile(r"^[AKNW][A-Z]?\d[A-Z]{1,3}$", re.IGNORECASE)


    def detect_cw_from_audio(audio_path: str) -> bool:
        """Return True if audio content appears to be CW (Morse code).

        Detects CW by checking for a bimodal dit/dah element structure in the
        amplitude envelope. Works even when CW is sent through FM repeaters,
        where spectral narrowness tests fail due to FM demodulation noise.
        Uses soundfile for fast loading (no resampling needed for envelope detection).
        """
        try:
            import soundfile as sf
            y, sr = sf.read(audio_path, dtype='float32', always_2d=False)
            if y.ndim > 1:
                y = y[:, 0]
        except Exception:
            return False
        if len(y) < sr * 0.3:
            return False

        frame_len = int(sr * 0.020)
        hop = frame_len // 2
        hop_ms = (hop / sr) * 1000
        envelope = np.array([
            float(np.sqrt(np.mean(y[i:i + frame_len] ** 2)))
            for i in range(0, len(y) - frame_len, hop)
        ])
        if len(envelope) < 6:
            return False
        max_env = float(np.max(envelope))
        if max_env == 0:
            return False
        on_off = (envelope / max_env) > 0.25

        current = bool(on_off[0])
        run = 1
        on_runs_ms = []
        for v in on_off[1:]:
            if bool(v) == current:
                run += 1
            else:
                if current:
                    on_runs_ms.append(run * hop_ms)
                current = bool(v)
                run = 1
        if current:
            on_runs_ms.append(run * hop_ms)

        cw_elements = [r for r in on_runs_ms if 30 <= r <= 700]
        # Minimum 10 elements: even the shortest callsign CW ID (e.g. W1A) has ≥10
        if len(cw_elements) < 10:
            return False

        # Rate check: real CW tops out at ~25 WPM = ~2.5 on-elements/s.
        duration_s = len(y) / sr
        if duration_s > 0 and len(cw_elements) / duration_s > 3.0:
            return False

        cw_arr = np.array(cw_elements)
        median = float(np.median(cw_arr))
        short_els = cw_arr[cw_arr <= median]
        long_els = cw_arr[cw_arr > median]

        if len(short_els) < 2 or len(long_els) < 2:
            return False

        short_mean = float(np.mean(short_els))
        long_mean = float(np.mean(long_els))

        if short_mean == 0:
            return False
        ratio = long_mean / short_mean
        # CW standard: dah = 3 × dit. Allow 2–5× to tolerate speed variation.
        if not (2.0 <= ratio <= 5.0):
            return False

        return True


    # DTMF frequency table: (row_hz, col_hz) -> digit
    _DTMF_ROWS = [697, 770, 852, 941]
    _DTMF_COLS = [1209, 1336, 1477, 1633]
    _DTMF_MAP = {
        (697, 1209): "1", (697, 1336): "2", (697, 1477): "3", (697, 1633): "A",
        (770, 1209): "4", (770, 1336): "5", (770, 1477): "6", (770, 1633): "B",
        (852, 1209): "7", (852, 1336): "8", (852, 1477): "9", (852, 1633): "C",
        (941, 1209): "*", (941, 1336): "0", (941, 1477): "#", (941, 1633): "D",
    }


    def _goertzel_power(samples: np.ndarray, target_hz: float, sample_rate: int) -> float:
        """Compute Goertzel algorithm power for a single frequency."""
        N = len(samples)
        k = int(0.5 + N * target_hz / sample_rate)
        omega = 2 * np.pi * k / N
        coeff = 2 * np.cos(omega)
        s_prev2 = s_prev = 0.0
        for x in samples:
            s = float(x) + coeff * s_prev - s_prev2
            s_prev2 = s_prev
            s_prev = s
        return s_prev2 ** 2 + s_prev ** 2 - coeff * s_prev * s_prev2


    def detect_dtmf_tones(audio_path: str) -> str | None:
        """
        Scan a WAV file for DTMF tones using Goertzel filters.
        Returns a string of detected digits (e.g. '1234#') or None if none found.
        Processes audio in 40ms windows with 50% overlap.
        """
        try:
            import wave, array as _array
            with wave.open(audio_path, "rb") as wf:
                sr = wf.getframerate()
                nchannels = wf.getnchannels()
                sampwidth = wf.getsampwidth()
                raw = wf.readframes(wf.getnframes())
            # Decode PCM
            if sampwidth == 2:
                samples = np.frombuffer(raw, dtype=np.int16).astype(np.float32) / 32768.0
            elif sampwidth == 1:
                samples = (np.frombuffer(raw, dtype=np.uint8).astype(np.float32) - 128) / 128.0
            else:
                return None
            if nchannels > 1:
                samples = samples[::nchannels]  # take first channel
            window_size = int(sr * 0.04)   # 40ms
            hop_size = window_size // 2
            if window_size < 64:
                return None
            digits = []
            prev_digit = None
            for start in range(0, len(samples) - window_size, hop_size):
                chunk = samples[start:start + window_size]
                # Energy check — skip silent windows
                rms = float(np.sqrt(np.mean(chunk ** 2)))
                if rms < 0.01:
                    prev_digit = None
                    continue
                # Find dominant row and col
                row_powers = {f: _goertzel_power(chunk, f, sr) for f in _DTMF_ROWS}
                col_powers = {f: _goertzel_power(chunk, f, sr) for f in _DTMF_COLS}
                best_row = max(row_powers, key=row_powers.get)
                best_col = max(col_powers, key=col_powers.get)
                # Validate: dominant freq should be significantly stronger than others
                row_vals = list(row_powers.values())
                col_vals = list(col_powers.values())
                row_second = sorted(row_vals)[-2] if len(row_vals) > 1 else 0
                col_second = sorted(col_vals)[-2] if len(col_vals) > 1 else 0
                if row_powers[best_row] < row_second * 3:
                    prev_digit = None
                    continue
                if col_powers[best_col] < col_second * 3:
                    prev_digit = None
                    continue
                digit = _DTMF_MAP.get((best_row, best_col))
                if digit and digit != prev_digit:
                    digits.append(digit)
                    prev_digit = digit
                elif not digit:
                    prev_digit = None
            return "".join(digits) if len(digits) >= 1 else None
        except Exception as exc:
            print(f"[DTMF] detection error for {audio_path}: {exc}")
            return None


    def ensure_recordings_schema(db):
        db.execute(text("ALTER TABLE recordings ADD COLUMN IF NOT EXISTS ai_tags TEXT"))
        db.execute(text("ALTER TABLE recordings ADD COLUMN IF NOT EXISTS repeater_id INTEGER"))
        db.execute(text("ALTER TABLE recordings ADD COLUMN IF NOT EXISTS frequency_label TEXT"))
        db.execute(text("ALTER TABLE recordings ADD COLUMN IF NOT EXISTS notes TEXT"))
        db.execute(text("ALTER TABLE recordings ADD COLUMN IF NOT EXISTS dtmf_tones TEXT"))
        db.execute(text("""
            CREATE TABLE IF NOT EXISTS alert_rules (
                id SERIAL PRIMARY KEY,
                rule_type TEXT NOT NULL,
                value TEXT NOT NULL,
                enabled BOOLEAN NOT NULL DEFAULT TRUE,
                notes TEXT,
                created_at TIMESTAMP DEFAULT NOW()
            )
        """))
        db.execute(text("""
            CREATE TABLE IF NOT EXISTS frequency_bookmarks (
                id SERIAL PRIMARY KEY,
                frequency_hz FLOAT NOT NULL,
                bandwidth_hz FLOAT DEFAULT 5000.0,
                label TEXT NOT NULL,
                notes TEXT,
                alert_on_activity BOOLEAN NOT NULL DEFAULT FALSE,
                created_at TIMESTAMP DEFAULT NOW()
            )
        """))
        db.commit()


    def safe_unlink(path: str | None):
        if not path:
            return
        try:
            os.remove(path)
        except OSError:
            pass


    def prune_missing_recordings():
        db = SessionLocal()
        removed = 0
        try:
            ensure_recordings_schema(db)
            recordings = db.query(Recording).all()
            for recording in recordings:
                if recording.audio_path:
                    # Has audio: prune if file missing
                    if not os.path.exists(recording.audio_path):
                        db.delete(recording)
                        removed += 1
                else:
                    # No audio (e.g. APRS text-only): prune if text also missing
                    if not recording.text_path or not os.path.exists(recording.text_path):
                        db.delete(recording)
                        removed += 1
            if removed:
                db.commit()
                print(f"Pruned {removed} stale recordings (missing files)")
        except Exception as e:
            print(f"Prune error: {e}")
            db.rollback()
        finally:
            db.close()


    APRS_BANDS_HZ = (
        (144_370_000, 144_410_000),
        (145_805_000, 145_845_000),
    )
    APRS_DECODE_FAILED_MARKER = "APRS_DECODE_FAILED"


    def is_aprs_frequency_hz(frequency_hz: float | None) -> bool:
        if frequency_hz is None:
            return False
        hz = int(round(frequency_hz))
        return any(low <= hz <= high for (low, high) in APRS_BANDS_HZ)


    def parse_voice_filename(filename: str) -> dict:
        match = re.match(r"(\d+)_(\d+)\.wav$", filename)
        if match:
            freq_hz = float(match.group(1))
            timestamp = datetime.fromtimestamp(int(match.group(2)))
            return {"frequency_hz": freq_hz, "timestamp": timestamp}
        return {}


    def parse_cw_filename(filename: str) -> dict:
        match = re.match(r"cw_(\d+)_(\d+)\.wav$", filename)
        if match:
            freq_hz = float(match.group(1))
            timestamp = datetime.fromtimestamp(int(match.group(2)))
            return {"frequency_hz": freq_hz, "timestamp": timestamp}
        match = re.match(r"cw_(\d+)\.wav$", filename)
        if match:
            freq_hz = float(match.group(1))
            return {"frequency_hz": freq_hz}
        return {}


    def get_audio_duration(audio_path: str) -> float:
        try:
            duration = librosa.get_duration(path=audio_path)
            return duration
        except Exception:
            return 0.0


    def read_transcript(text_path: str) -> str | None:
        if os.path.exists(text_path):
            try:
                with open(text_path, "r") as f:
                    return f.read().strip()
            except Exception:
                pass
        return None


    def update_search_vector(db, recording_id: int, transcript: str):
        db.execute(
            text(
                "UPDATE recordings SET search_vector = to_tsvector('english', :transcript) WHERE id = :id"
            ),
            {"transcript": transcript, "id": recording_id},
        )
        db.commit()


    def sanitize_tag(tag: str) -> str | None:
        text_tag = tag.strip()
        if not text_tag:
            return None
        upper_tag = text_tag.upper()
        if CALLSIGN_TAG_PATTERN.match(upper_tag):
            return upper_tag
        lowered = text_tag.lower().replace("-", " ")
        lowered = re.sub(r"[^a-z0-9_ ]+", "", lowered)
        lowered = re.sub(r"\s+", "_", lowered).strip("_")
        if len(lowered) < 2 or len(lowered) > 48:
            return None
        return lowered


    def build_ollama_prompt(transcript, callsign_tags, frequency_label=None, repeater_info=None, operator_context=None):
        callsign_context = ", ".join(callsign_tags) if callsign_tags else "none"
        clipped = transcript.strip()
        if len(clipped) > 1600:
            clipped = clipped[:1600]
        context_lines = [f"Known callsigns: {callsign_context}"]
        if operator_context:
            context_lines.append(f"Operators:\n{operator_context}")
        if frequency_label:
            context_lines.append(f"Frequency: {frequency_label}")
        if repeater_info:
            context_lines.append(f"Repeater: {repeater_info}")
        context = "\n".join(context_lines)
        return (
            "You tag radio transcripts for later filtering. "
            "Return ONLY valid JSON with this exact schema: "
            "{\"tags\":[\"tag_one\",\"tag_two\"]}. "
            "Rules: 3 to 8 concise tags, no sentences, no duplicates, "
            "prefer lowercase underscore tags, include callsign tags when relevant.\n\n"
            f"{context}\n"
            f"Transcript:\n{clipped}"
        )


    def generate_ollama_tags(transcript, frequency_label=None, repeater_info=None, operator_context=None):
        if not settings.ollama_enabled:
            return []
        if not transcript or is_no_speech_transcript(transcript):
            return []
        callsign_tags = extract_callsign_tags(transcript)
        payload = {
            "model": settings.ollama_model,
            "stream": False,
            "format": "json",
            "options": {"temperature": 0.1},
            "prompt": build_ollama_prompt(
                transcript, callsign_tags,
                frequency_label=frequency_label,
                repeater_info=repeater_info,
                operator_context=operator_context,
            ),
        }
        endpoint = settings.ollama_url.rstrip("/") + "/api/generate"
        req = request.Request(
            endpoint,
            data=json.dumps(payload).encode("utf-8"),
            headers={"Content-Type": "application/json"},
            method="POST",
        )
        try:
            indexer_ollama_calls.inc()
            with request.urlopen(req, timeout=settings.ollama_timeout_seconds) as resp:
                body = resp.read().decode("utf-8", errors="ignore")
        except error.URLError as exc:
            indexer_ollama_errors.inc()
            print(f"Ollama request failed: {exc}")
            return callsign_tags
        except Exception as exc:
            indexer_ollama_errors.inc()
            print(f"Ollama request error: {exc}")
            return callsign_tags
        tags: list[str] = []
        seen = set()
        for tag in callsign_tags:
            cleaned = sanitize_tag(tag)
            if cleaned and cleaned not in seen:
                seen.add(cleaned)
                tags.append(cleaned)
        try:
            outer = json.loads(body)
            response_text = outer.get("response", "")
        except Exception:
            response_text = ""
        parsed_tags: list[str] = []
        if response_text:
            try:
                parsed = json.loads(response_text)
                if isinstance(parsed, dict) and isinstance(parsed.get("tags"), list):
                    parsed_tags = [str(v) for v in parsed["tags"]]
                elif isinstance(parsed, list):
                    parsed_tags = [str(v) for v in parsed]
            except Exception:
                parsed_tags = [p.strip() for p in re.split(r"[,\n]", response_text) if p.strip()]
        max_tags = max(1, settings.ollama_max_tags)
        for raw_tag in parsed_tags:
            cleaned = sanitize_tag(raw_tag)
            if cleaned and cleaned not in seen:
                seen.add(cleaned)
                tags.append(cleaned)
            if len(tags) >= max_tags:
                break
        return tags


    def maybe_set_ai_tags(db, recording, transcript, ollama_budget, hamdb_budget=None):
        if recording.ai_tags:
            return
        if not transcript or is_no_speech_transcript(transcript):
            return
        if ollama_budget["remaining"] <= 0 and not settings.ollama_enabled:
            return
        seed_tags: list[str] = []
        if recording.repeater_id:
            from .repeater import repeater_tags as get_repeater_tags
            from ..models import Repeater
            rptr = db.query(Repeater).filter(Repeater.id == recording.repeater_id).first()
            if rptr:
                seed_tags = get_repeater_tags(rptr)
        if not settings.ollama_enabled:
            if seed_tags:
                recording.ai_tags = dump_ai_tags(seed_tags)
            return
        if ollama_budget["remaining"] <= 0:
            if seed_tags:
                recording.ai_tags = dump_ai_tags(seed_tags)
            return
        ollama_budget["remaining"] -= 1
        repeater_info = None
        if recording.repeater_id:
            from ..models import Repeater
            rptr = db.query(Repeater).filter(Repeater.id == recording.repeater_id).first()
            if rptr:
                repeater_info = f"{rptr.callsign} ({rptr.location}, {rptr.state})"
                if rptr.county:
                    repeater_info += f", {rptr.county} county"
                if rptr.pl_tone:
                    repeater_info += f" PL {rptr.pl_tone:.1f} Hz"
                if rptr.digital_modes:
                    repeater_info += f" [{rptr.digital_modes}]"
                if rptr.linked_nodes:
                    repeater_info += f" nodes:{rptr.linked_nodes}"
        operator_context = None
        callsigns = extract_callsign_tags(transcript)
        if callsigns and hamdb_budget is not None:
            info_map = lookup_callsigns(db, callsigns, hamdb_budget)
            operator_context = callsign_context_str(info_map)
        tags = generate_ollama_tags(
            transcript,
            frequency_label=recording.frequency_label,
            repeater_info=repeater_info,
            operator_context=operator_context,
        )
        merged = list(dict.fromkeys(seed_tags + tags))
        serialized = dump_ai_tags(merged)
        if serialized:
            recording.ai_tags = serialized


    def should_auto_delete_no_speech(transcript: str | None) -> bool:
        return settings.auto_delete_no_speech and is_no_speech_transcript(transcript)


    def maybe_set_frequency_metadata(db, recording):
        if recording.frequency_hz is None:
            return
        if recording.frequency_label is None:
            # Check user-defined DB labels first, then fall back to static known_freqs
            try:
                from ..models import FrequencyLabel
                db_label = db.execute(
                    text(
                        "SELECT label FROM frequency_labels"
                        " WHERE ABS(frequency_hz - :f) <= COALESCE(bandwidth_hz, 5000)"
                        " ORDER BY ABS(frequency_hz - :f) LIMIT 1"
                    ),
                    {"f": recording.frequency_hz},
                ).first()
                if db_label:
                    recording.frequency_label = db_label[0]
            except Exception:
                pass
            if recording.frequency_label is None:
                label = lookup_known_freq(recording.frequency_hz)
                if label:
                    recording.frequency_label = label
        if recording.repeater_id is None:
            rptr = lookup_repeater(db, recording.frequency_hz)
            if rptr:
                recording.repeater_id = rptr.id
                recording.frequency_label = repeater_label(rptr)


    def index_directory(mode: str, audio_dir: str, text_dir: str, ollama_budget: dict, hamdb_budget: dict | None = None):
        db = SessionLocal()
        try:
            ensure_recordings_schema(db)
            audio_path = Path(audio_dir)
            if not audio_path.exists():
                return
            for wav_file in audio_path.glob("*.wav"):
                filename = wav_file.name
                if mode == "voice":
                    metadata = parse_voice_filename(filename)
                    # APRS-band captures are indexed only by the APRS pipeline.
                    if is_aprs_frequency_hz(metadata.get("frequency_hz")):
                        continue
                else:
                    metadata = parse_cw_filename(filename)
                text_path = os.path.join(text_dir, filename.replace(".wav", ".txt"))
                existing = db.query(Recording).filter(Recording.filename == filename).first()
                if existing:
                    if should_auto_delete_no_speech(existing.transcript):
                        safe_unlink(existing.audio_path)
                        safe_unlink(existing.text_path)
                        safe_unlink(existing.waveform_cached)
                        safe_unlink(existing.spectrogram_cached)
                        db.delete(existing)
                        db.commit()
                        print(f"Auto-deleted no-speech recording: {filename}")
                        continue
                    if existing.transcript is None:
                        transcript = read_transcript(text_path)
                        if transcript:
                            if should_auto_delete_no_speech(transcript):
                                safe_unlink(str(wav_file))
                                safe_unlink(text_path)
                                db.delete(existing)
                                db.commit()
                                print(f"Auto-deleted no-speech recording: {filename}")
                                continue
                            existing.text_path = text_path
                            existing.transcript = transcript
                            update_search_vector(db, existing.id, transcript)
                    maybe_set_frequency_metadata(db, existing)
                    maybe_set_ai_tags(db, existing, existing.transcript, ollama_budget, hamdb_budget)
                    check_alerts(existing, db)
                    db.commit()
                    continue
                timestamp = metadata.get("timestamp")
                if timestamp is None:
                    try:
                        timestamp = datetime.fromtimestamp(wav_file.stat().st_mtime)
                    except Exception:
                        timestamp = None
                duration = get_audio_duration(str(wav_file))
                transcript = read_transcript(text_path)
                if should_auto_delete_no_speech(transcript):
                    safe_unlink(str(wav_file))
                    safe_unlink(text_path)
                    print(f"Auto-deleted no-speech recording: {filename}")
                    continue
                effective_mode = mode
                if mode == "voice":
                    try:
                        if detect_cw_from_audio(str(wav_file)):
                            effective_mode = "cw"
                            transcript = None
                            safe_unlink(text_path)
                            print(f"[CW-DETECT] Reclassified {filename} as CW")
                    except Exception as _cw_err:
                        print(f"[CW-DETECT] Error on {filename}: {_cw_err}")
                recording = Recording(
                    filename=filename,
                    mode=effective_mode,
                    frequency_hz=metadata.get("frequency_hz"),
                    timestamp=timestamp,
                    duration_seconds=duration,
                    audio_path=str(wav_file),
                    text_path=text_path if transcript else None,
                    transcript=transcript,
                )
                recording.signal_db = compute_signal_db(str(wav_file))
                maybe_set_frequency_metadata(db, recording)
                # DTMF detection for voice recordings
                if effective_mode == "voice" and recording.audio_path:
                    try:
                        dtmf = detect_dtmf_tones(recording.audio_path)
                        if dtmf:
                            recording.dtmf_tones = dtmf
                            print(f"[DTMF] '{dtmf}' in {filename}")
                    except Exception as _dtmf_err:
                        print(f"[DTMF] error on {filename}: {_dtmf_err}")
                # Weather radio auto-tagging
                if recording.frequency_label and "NOAA WX" in recording.frequency_label:
                    wx_tags = ["weather_radio"]
                    if recording.transcript:
                        t_upper = recording.transcript.upper()
                        if any(k in t_upper for k in [
                            "TORNADO", "FLOOD", "SEVERE", "EMERGENCY",
                            "WARNING", "WATCH", "ADVISORY", "SAME",
                        ]):
                            wx_tags.append("weather_alert")
                    existing_ai = parse_ai_tags(recording.ai_tags)
                    recording.ai_tags = dump_ai_tags(list(dict.fromkeys(wx_tags + existing_ai)))
                maybe_set_ai_tags(db, recording, transcript, ollama_budget, hamdb_budget)
                check_alerts(recording, db)
                # Frequency bookmark activity webhook
                try:
                    if recording.frequency_hz and settings.alert_webhook_url:
                        bm_rows = db.execute(
                            text(
                                "SELECT id, label FROM frequency_bookmarks"
                                " WHERE alert_on_activity = TRUE"
                                " AND ABS(frequency_hz - :f) <= COALESCE(bandwidth_hz, 5000)"
                            ),
                            {"f": recording.frequency_hz},
                        ).fetchall()
                        for bm in bm_rows:
                            from ..services.alerting import _send_webhook
                            _send_webhook({
                                "type": "bookmark_activity",
                                "bookmark_id": bm.id,
                                "bookmark_label": bm.label,
                                "recording_id": recording.id if recording.id else 0,
                                "filename": recording.filename,
                                "frequency_hz": recording.frequency_hz,
                                "frequency_label": recording.frequency_label,
                                "timestamp": recording.timestamp.isoformat() if recording.timestamp else None,
                            })
                except Exception as _bm_err:
                    print(f"[Bookmark] activity check error: {_bm_err}")
                db.add(recording)
                db.commit()
                if transcript:
                    update_search_vector(db, recording.id, transcript)
                indexer_files_indexed.labels(mode=effective_mode).inc()
                print(f"Indexed: {filename}")
                try:
                    import asyncio as _asyncio
                    from ..routers.events import broadcast_recording as _broadcast
                    _asyncio.get_event_loop().call_soon_threadsafe(
                        lambda: _asyncio.ensure_future(_broadcast({
                            "id": recording.id,
                            "mode": recording.mode,
                            "frequency_hz": recording.frequency_hz,
                            "frequency_label": recording.frequency_label,
                            "timestamp": recording.timestamp.isoformat() if recording.timestamp else None,
                            "duration_seconds": recording.duration_seconds,
                            "has_transcript": bool((recording.transcript or "").strip()),
                            "signal_db": recording.signal_db,
                        }))
                    )
                except Exception:
                    pass
        except Exception as e:
            print(f"Indexer error: {e}")
            db.rollback()
        finally:
            db.close()


    def index_aprs_directory(text_dir: str):
        """Index APRS packets from text-only files (audio deleted after decode)."""
        db = SessionLocal()
        try:
            ensure_recordings_schema(db)
            text_path = Path(text_dir)
            if not text_path.exists():
                return
            for txt_file in text_path.glob("*.txt"):
                wav_name = txt_file.name.replace(".txt", ".wav")
                existing = db.query(Recording).filter(Recording.filename == wav_name).first()
                if existing:
                    continue
                metadata = parse_voice_filename(wav_name)
                timestamp = metadata.get("timestamp")
                if timestamp is None:
                    try:
                        timestamp = datetime.fromtimestamp(txt_file.stat().st_mtime)
                    except Exception:
                        timestamp = None
                transcript = read_transcript(str(txt_file))
                if not transcript:
                    continue
                transcript = transcript.strip()
                if not transcript:
                    continue
                decode_failed = transcript.upper().startswith(APRS_DECODE_FAILED_MARKER)
                recording = Recording(
                    filename=wav_name,
                    mode="aprs",
                    frequency_hz=metadata.get("frequency_hz"),
                    timestamp=timestamp,
                    duration_seconds=None,
                    audio_path=None,
                    text_path=str(txt_file),
                    transcript=transcript,
                )
                maybe_set_frequency_metadata(db, recording)
                if decode_failed:
                    recording.ai_tags = dump_ai_tags(["aprs", "decode_failed"])
                else:
                    # Tag with callsigns from the packet (no Ollama for structured APRS data)
                    callsign_tags = extract_callsign_tags(transcript)
                    if callsign_tags:
                        recording.ai_tags = dump_ai_tags(callsign_tags)
                check_alerts(recording, db)
                db.add(recording)
                db.commit()
                if transcript:
                    update_search_vector(db, recording.id, transcript)
                aprs_packets_indexed.inc()
                print(f"Indexed APRS: {txt_file.name}")
        except Exception as e:
            print(f"APRS indexer error: {e}")
            db.rollback()
        finally:
            db.close()


    def _refresh_db_gauges():
        """Query DB and update Prometheus gauge metrics. Called once per cycle."""
        from sqlalchemy import func as _func
        from ..models import Repeater
        _db = SessionLocal()
        try:
            for _mode, _cnt in _db.query(Recording.mode, _func.count(Recording.id)).group_by(Recording.mode).all():
                if _mode:
                    recordings_total.labels(mode=_mode).set(_cnt)
            recordings_with_transcript.set(
                _db.query(_func.count(Recording.id)).filter(Recording.transcript.isnot(None)).scalar() or 0
            )
            recordings_with_ai_tags.set(
                _db.query(_func.count(Recording.id)).filter(Recording.ai_tags.isnot(None)).scalar() or 0
            )
            recordings_with_repeater.set(
                _db.query(_func.count(Recording.id)).filter(Recording.repeater_id.isnot(None)).scalar() or 0
            )
            recordings_pending_transcript.set(
                _db.query(_func.count(Recording.id)).filter(
                    Recording.mode.in_(["voice", "cw"]), Recording.transcript.is_(None)
                ).scalar() or 0
            )
            recordings_pending_ai_tags.set(
                _db.query(_func.count(Recording.id)).filter(
                    Recording.ai_tags.is_(None), Recording.transcript.isnot(None)
                ).scalar() or 0
            )
            recordings_pending_freq_label.set(
                _db.query(_func.count(Recording.id)).filter(
                    Recording.frequency_hz.isnot(None), Recording.frequency_label.is_(None)
                ).scalar() or 0
            )
            repeater_count.set(_db.query(_func.count(Repeater.id)).scalar() or 0)
            _last_synced = _db.query(_func.max(Repeater.last_synced)).scalar()
            if _last_synced:
                repeater_sync_age_seconds.set(_time.time() - _last_synced.timestamp())
        except Exception as _e:
            print(f"[metrics] DB gauge refresh error: {_e}")
        finally:
            _db.close()


    # Track last auto-retention and digest run times
    _last_auto_retention: float = 0.0
    _last_daily_digest: float = 0.0
    _last_digest_sent: datetime | None = None
    _AUTO_RETENTION_INTERVAL = 86400.0   # 24 hours
    _DAILY_DIGEST_INTERVAL = 86400.0     # 24 hours


    def _run_auto_retention():
        """Delete recordings older than RETENTION_DAYS. Runs at most once per day."""
        if settings.retention_days <= 0:
            return
        db = SessionLocal()
        try:
            cutoff = datetime.utcnow() - timedelta(days=settings.retention_days)
            recordings = db.query(Recording).filter(Recording.timestamp < cutoff).all()
            deleted = 0
            for rec in recordings:
                for path in [rec.audio_path, rec.text_path, rec.waveform_cached, rec.spectrogram_cached]:
                    if path:
                        try:
                            os.remove(path)
                        except OSError:
                            pass
                db.delete(rec)
                deleted += 1
            db.commit()
            if deleted:
                print(f"[AutoRetention] Deleted {deleted} recordings older than {settings.retention_days} days")
        except Exception as exc:
            print(f"[AutoRetention] error: {exc}")
            db.rollback()
        finally:
            db.close()


    def _send_daily_digest():
        """Send a daily summary webhook with recording stats."""
        if not settings.alert_webhook_url:
            return
        db = SessionLocal()
        try:
            from sqlalchemy import func as _func
            cutoff_24h = datetime.utcnow() - timedelta(hours=24)
            total_24h = db.query(_func.count(Recording.id)).filter(
                Recording.timestamp >= cutoff_24h
            ).scalar() or 0
            by_mode = {}
            for mode, cnt in db.query(Recording.mode, _func.count(Recording.id)).filter(
                Recording.timestamp >= cutoff_24h
            ).group_by(Recording.mode).all():
                by_mode[mode or "unknown"] = cnt
            top_freqs = db.query(
                Recording.frequency_label, _func.count(Recording.id).label("cnt")
            ).filter(
                Recording.timestamp >= cutoff_24h,
                Recording.frequency_label.isnot(None),
            ).group_by(Recording.frequency_label).order_by(
                _func.count(Recording.id).desc()
            ).limit(5).all()
            alerts_24h = db.query(_func.count(Recording.id)).join(
                Recording,
                (Recording.id == Recording.id),  # placeholder — use AlertHistory
            ).scalar() or 0
            from ..services.alerting import _send_webhook
            _send_webhook({
                "type": "daily_digest",
                "period_hours": 24,
                "total_recordings": total_24h,
                "by_mode": by_mode,
                "top_frequencies": [{"label": lbl, "count": cnt} for lbl, cnt in top_freqs],
                "generated_at": datetime.utcnow().isoformat(),
            })
            print(f"[DailyDigest] Sent: {total_24h} recordings in last 24h")
        except Exception as exc:
            print(f"[DailyDigest] error: {exc}")
        finally:
            db.close()


    async def run_indexer():
        while True:
            _cycle_start = _time.time()
            try:
                await asyncio.to_thread(prune_missing_recordings)

                ollama_budget = {"remaining": max(0, settings.ollama_max_per_cycle)}
                hamdb_budget = {"remaining": max(0, settings.hamdb_max_per_cycle)}

                await asyncio.to_thread(
                    index_directory,
                    mode="voice",
                    audio_dir=os.path.join(settings.audio_base_path, "voice"),
                    text_dir=os.path.join(settings.text_base_path, "voice"),
                    ollama_budget=ollama_budget,
                    hamdb_budget=hamdb_budget,
                )

                await asyncio.to_thread(
                    index_directory,
                    mode="cw",
                    audio_dir=os.path.join(settings.audio_base_path, "cw"),
                    text_dir=os.path.join(settings.text_base_path, "cw"),
                    ollama_budget=ollama_budget,
                    hamdb_budget=hamdb_budget,
                )

                await asyncio.to_thread(
                    index_aprs_directory,
                    text_dir=os.path.join(settings.text_base_path, "aprs"),
                )

                await asyncio.to_thread(_refresh_db_gauges)

            except Exception as e:
                print(f"Indexer cycle error: {e}")

            indexer_cycle_duration.observe(_time.time() - _cycle_start)
            indexer_last_run.set(_time.time())

            # Scheduled auto-retention (once per day)
            global _last_auto_retention
            if _time.time() - _last_auto_retention >= _AUTO_RETENTION_INTERVAL:
                try:
                    await asyncio.to_thread(_run_auto_retention)
                    _last_auto_retention = _time.time()
                except Exception as _ar_err:
                    print(f"[AutoRetention] task error: {_ar_err}")

            # Daily digest webhook (once per day, offset 1 hour from retention)
            global _last_daily_digest
            if _time.time() - _last_daily_digest >= _DAILY_DIGEST_INTERVAL:
                try:
                    await asyncio.to_thread(_send_daily_digest)
                    _last_daily_digest = _time.time()
                except Exception as _dd_err:
                    print(f"[DailyDigest] task error: {_dd_err}")

            # SDR hardware health
            try:
                import glob as _glob
                _wavs = _glob.glob(os.path.join(settings.audio_base_path, "voice", "*.wav"))
                if _wavs:
                    sdr_hardware_last_seen_seconds.set(_time.time() - max(os.path.getmtime(f) for f in _wavs))
            except Exception:
                pass

            # Heartbeat for liveness probe
            try:
                with open("/tmp/indexer_heartbeat", "w") as _hb:
                    _hb.write(str(_time.time()))
            except Exception:
                pass

            await asyncio.sleep(30)

  admin.py: |
    import asyncio
    import glob as _glob
    import json
    import os
    import shutil
    import time as _time
    from datetime import datetime, timedelta

    from fastapi import APIRouter, Depends, HTTPException
    from pydantic import BaseModel
    from sqlalchemy import func, text as _sql_text
    from sqlalchemy.orm import Session

    from ..config import settings
    from ..database import get_db
    from ..models import AlertHistory, FrequencyLabel, Recording, Repeater
    from ..services.alerting import _send_webhook
    from ..services.indexer import maybe_set_frequency_metadata
    from ..services.repeater import sync_repeaters

    router = APIRouter()


    @router.post("/backfill-frequency")
    async def backfill_frequency(
        limit: int = 500,
        db: Session = Depends(get_db),
    ):
        recordings = (
            db.query(Recording)
            .filter(
                Recording.frequency_hz.isnot(None),
                Recording.frequency_label.is_(None),
            )
            .limit(limit)
            .all()
        )
        updated = 0
        for rec in recordings:
            before_label = rec.frequency_label
            before_repeater = rec.repeater_id
            maybe_set_frequency_metadata(db, rec)
            if rec.frequency_label != before_label or rec.repeater_id != before_repeater:
                updated += 1
        db.commit()
        return {"scanned": len(recordings), "updated": updated}


    @router.post("/sync-repeaters")
    async def trigger_repeater_sync():
        asyncio.create_task(asyncio.to_thread(sync_repeaters))
        return {"status": "sync started"}


    @router.get("/status")
    async def get_status(db: Session = Depends(get_db)):
        total_repeaters = db.query(func.count(Repeater.id)).scalar() or 0
        last_synced = db.query(func.max(Repeater.last_synced)).scalar()
        by_state = (
            db.query(Repeater.state, func.count(Repeater.id))
            .filter(Repeater.state.isnot(None))
            .group_by(Repeater.state)
            .order_by(func.count(Repeater.id).desc())
            .all()
        )
        total_recordings = db.query(func.count(Recording.id)).scalar() or 0
        pending_freq = (
            db.query(func.count(Recording.id))
            .filter(
                Recording.frequency_hz.isnot(None),
                Recording.frequency_label.is_(None),
            )
            .scalar() or 0
        )
        pending_tags = (
            db.query(func.count(Recording.id))
            .filter(Recording.ai_tags.is_(None), Recording.transcript.isnot(None))
            .scalar() or 0
        )
        pending_transcripts = (
            db.query(func.count(Recording.id))
            .filter(
                Recording.mode.in_(["voice", "cw"]),
                Recording.transcript.is_(None),
            )
            .scalar() or 0
        )
        sdr_last_seen_seconds = None
        try:
            wav_files = _glob.glob(os.path.join(settings.audio_base_path, "voice", "*.wav"))
            if wav_files:
                newest_mtime = max(os.path.getmtime(f) for f in wav_files)
                sdr_last_seen_seconds = int(_time.time() - newest_mtime)
        except Exception:
            pass
        return {
            "total_repeaters": total_repeaters,
            "last_repeater_sync": last_synced.isoformat() if last_synced else None,
            "repeaters_by_state": {state: cnt for state, cnt in by_state},
            "total_recordings": total_recordings,
            "pending_freq_label": pending_freq,
            "pending_ai_tags": pending_tags,
            "pending_transcripts": pending_transcripts,
            "sdr_last_seen_seconds": sdr_last_seen_seconds,
        }


    @router.get("/alerts")
    async def list_alerts(
        limit: int = 100,
        db: Session = Depends(get_db),
    ):
        rows = (
            db.query(AlertHistory)
            .order_by(AlertHistory.timestamp.desc())
            .limit(limit)
            .all()
        )
        return {
            "total": db.query(func.count(AlertHistory.id)).scalar() or 0,
            "items": [
                {
                    "id": r.id,
                    "timestamp": r.timestamp.isoformat() if r.timestamp else None,
                    "recording_id": r.recording_id,
                    "filename": r.filename,
                    "frequency_hz": r.frequency_hz,
                    "frequency_label": r.frequency_label,
                    "transcript_excerpt": r.transcript_excerpt,
                    "matched": json.loads(r.matched) if r.matched else [],
                }
                for r in rows
            ],
        }


    @router.post("/alerts/{alert_id}/resend")
    async def resend_alert(alert_id: int, db: Session = Depends(get_db)):
        """Re-fire the webhook for a specific alert history entry."""
        ah = db.query(AlertHistory).filter(AlertHistory.id == alert_id).first()
        if not ah:
            raise HTTPException(status_code=404, detail="Alert not found")
        if not settings.alert_webhook_url:
            raise HTTPException(status_code=400, detail="No webhook URL configured")

        payload = {
            "recording_id": ah.recording_id,
            "filename": ah.filename,
            "frequency_hz": ah.frequency_hz,
            "frequency_label": ah.frequency_label,
            "timestamp": ah.timestamp.isoformat() if ah.timestamp else None,
            "transcript": ah.transcript_excerpt,
            "matched": json.loads(ah.matched) if ah.matched else [],
            "resent": True,
        }
        _send_webhook(payload)
        return {"status": "sent", "alert_id": alert_id}


    @router.get("/storage")
    async def get_storage():
        def _dir_size(path: str) -> int:
            total = 0
            if not os.path.isdir(path):
                return total
            for dirpath, _, filenames in os.walk(path):
                for f in filenames:
                    try:
                        total += os.path.getsize(os.path.join(dirpath, f))
                    except OSError:
                        pass
            return total

        def _dir_count(path: str) -> int:
            if not os.path.isdir(path):
                return 0
            return sum(1 for _, _, files in os.walk(path) for _ in files)

        audio_bytes = _dir_size(settings.audio_base_path)
        cache_bytes = _dir_size(settings.cache_path)
        try:
            usage = shutil.disk_usage(settings.audio_base_path)
            free_bytes = usage.free
            total_bytes = usage.total
        except Exception:
            free_bytes = 0
            total_bytes = 0
        return {
            "audio_bytes": audio_bytes,
            "audio_files": _dir_count(settings.audio_base_path),
            "cache_bytes": cache_bytes,
            "free_bytes": free_bytes,
            "total_bytes": total_bytes,
        }


    @router.post("/retention")
    async def run_retention(
        days: int = 0,
        dry_run: bool = False,
        mode: str | None = None,
        db: Session = Depends(get_db),
    ):
        effective_days = days if days > 0 else settings.retention_days
        if effective_days <= 0:
            raise HTTPException(status_code=400, detail="Specify days > 0 or set RETENTION_DAYS env var")
        cutoff = datetime.utcnow() - timedelta(days=effective_days)
        q = db.query(Recording).filter(Recording.timestamp < cutoff)
        if mode:
            q = q.filter(Recording.mode == mode)
        recordings = q.all()
        matched = len(recordings)
        if dry_run:
            return {"days": effective_days, "cutoff": cutoff.isoformat(), "matched": matched, "deleted": 0}
        deleted = 0
        for rec in recordings:
            for path in [rec.audio_path, rec.text_path, rec.waveform_cached, rec.spectrogram_cached]:
                if path:
                    try:
                        os.remove(path)
                    except OSError:
                        pass
            db.delete(rec)
            deleted += 1
        db.commit()
        return {"days": effective_days, "cutoff": cutoff.isoformat(), "matched": matched, "deleted": deleted}


    class FrequencyLabelCreate(BaseModel):
        frequency_hz: float
        bandwidth_hz: float = 5000.0
        label: str
        mode: str | None = None
        notes: str | None = None


    @router.get("/frequency-labels")
    async def list_frequency_labels(db: Session = Depends(get_db)):
        rows = db.query(FrequencyLabel).order_by(FrequencyLabel.frequency_hz).all()
        return {
            "items": [
                {
                    "id": r.id,
                    "frequency_hz": r.frequency_hz,
                    "bandwidth_hz": r.bandwidth_hz,
                    "label": r.label,
                    "mode": r.mode,
                    "notes": r.notes,
                    "created_at": r.created_at.isoformat() if r.created_at else None,
                }
                for r in rows
            ]
        }


    @router.post("/frequency-labels", status_code=201)
    async def create_frequency_label(
        body: FrequencyLabelCreate,
        db: Session = Depends(get_db),
    ):
        if not body.label.strip():
            raise HTTPException(status_code=422, detail="label cannot be empty")
        fl = FrequencyLabel(
            frequency_hz=body.frequency_hz,
            bandwidth_hz=body.bandwidth_hz,
            label=body.label.strip(),
            mode=body.mode,
            notes=body.notes,
        )
        db.add(fl)
        db.commit()
        db.refresh(fl)
        return {
            "id": fl.id,
            "frequency_hz": fl.frequency_hz,
            "bandwidth_hz": fl.bandwidth_hz,
            "label": fl.label,
            "mode": fl.mode,
            "notes": fl.notes,
            "created_at": fl.created_at.isoformat() if fl.created_at else None,
        }


    @router.delete("/frequency-labels/{label_id}")
    async def delete_frequency_label(label_id: int, db: Session = Depends(get_db)):
        fl = db.query(FrequencyLabel).filter(FrequencyLabel.id == label_id).first()
        if not fl:
            raise HTTPException(status_code=404, detail="Frequency label not found")
        db.delete(fl)
        db.commit()
        return {"deleted": label_id}


    @router.get("/sdr-health")
    async def get_sdr_health():
        last_seen_seconds = None
        last_seen_at = None
        healthy = False
        status = "no_files"
        try:
            wav_files = _glob.glob(os.path.join(settings.audio_base_path, "voice", "*.wav"))
            if wav_files:
                newest_mtime = max(os.path.getmtime(f) for f in wav_files)
                last_seen_seconds = int(_time.time() - newest_mtime)
                last_seen_at = datetime.fromtimestamp(newest_mtime).isoformat()
                healthy = last_seen_seconds < 300
                status = "ok" if healthy else "stale"
        except Exception as exc:
            status = f"error: {exc}"
        return {
            "last_seen_seconds": last_seen_seconds,
            "last_seen_at": last_seen_at,
            "healthy": healthy,
            "status": status,
        }


    @router.post("/bulk-retranscribe")
    async def bulk_retranscribe(
        clear_no_speech_only: bool = True,
        db: Session = Depends(get_db),
    ):
        from ..services.tagging import is_no_speech_transcript
        query = db.query(Recording).filter(
            Recording.mode.in_(["voice", "cw"]),
            Recording.transcript.isnot(None),
        )
        all_recs = query.all()
        if clear_no_speech_only:
            recs = [r for r in all_recs if is_no_speech_transcript(r.transcript)]
        else:
            recs = all_recs
        cleared = 0
        for rec in recs:
            if rec.text_path and os.path.exists(rec.text_path):
                try:
                    os.remove(rec.text_path)
                except OSError:
                    pass
            rec.transcript = None
            rec.text_path = None
            rec.ai_tags = None
            db.execute(
                _sql_text("UPDATE recordings SET search_vector = NULL WHERE id = :id"),
                {"id": rec.id},
            )
            cleared += 1
        db.commit()
        return {
            "cleared": cleared,
            "mode": "no_speech_only" if clear_no_speech_only else "all_voice_cw",
        }


    # ---------------------------------------------------------------------------
    # Alert rules (DB-backed keyword / callsign watches)
    # ---------------------------------------------------------------------------

    def _ensure_alert_rules(db):
        db.execute(_sql_text("""
            CREATE TABLE IF NOT EXISTS alert_rules (
                id SERIAL PRIMARY KEY,
                rule_type TEXT NOT NULL,
                value TEXT NOT NULL,
                enabled BOOLEAN NOT NULL DEFAULT TRUE,
                notes TEXT,
                created_at TIMESTAMP DEFAULT NOW()
            )
        """))
        db.commit()


    class AlertRuleCreate(BaseModel):
        rule_type: str   # 'keyword' or 'callsign'
        value: str
        notes: str | None = None


    @router.get("/alert-rules")
    async def list_alert_rules(db: Session = Depends(get_db)):
        _ensure_alert_rules(db)
        rows = db.execute(_sql_text(
            "SELECT id, rule_type, value, enabled, notes, created_at"
            " FROM alert_rules ORDER BY created_at DESC"
        )).fetchall()
        return {"items": [dict(r._mapping) for r in rows]}


    @router.post("/alert-rules", status_code=201)
    async def create_alert_rule(body: AlertRuleCreate, db: Session = Depends(get_db)):
        if body.rule_type not in ("keyword", "callsign"):
            raise HTTPException(status_code=422, detail="rule_type must be 'keyword' or 'callsign'")
        if not body.value.strip():
            raise HTTPException(status_code=422, detail="value cannot be empty")
        _ensure_alert_rules(db)
        val = (body.value.strip().upper() if body.rule_type == "callsign"
               else body.value.strip().lower())
        row = db.execute(
            _sql_text(
                "INSERT INTO alert_rules (rule_type, value, notes)"
                " VALUES (:rt, :v, :n)"
                " RETURNING id, rule_type, value, enabled, notes, created_at"
            ),
            {"rt": body.rule_type, "v": val, "n": body.notes},
        ).first()
        db.commit()
        return dict(row._mapping)


    @router.patch("/alert-rules/{rule_id}")
    async def toggle_alert_rule(rule_id: int, enabled: bool, db: Session = Depends(get_db)):
        _ensure_alert_rules(db)
        res = db.execute(
            _sql_text("UPDATE alert_rules SET enabled = :e WHERE id = :id RETURNING id"),
            {"e": enabled, "id": rule_id},
        ).first()
        if not res:
            raise HTTPException(status_code=404, detail="Rule not found")
        db.commit()
        return {"id": rule_id, "enabled": enabled}


    @router.delete("/alert-rules/{rule_id}")
    async def delete_alert_rule(rule_id: int, db: Session = Depends(get_db)):
        _ensure_alert_rules(db)
        res = db.execute(
            _sql_text("DELETE FROM alert_rules WHERE id = :id RETURNING id"),
            {"id": rule_id},
        ).first()
        if not res:
            raise HTTPException(status_code=404, detail="Rule not found")
        db.commit()
        return {"deleted": rule_id}


    @router.post("/test-webhook")
    async def test_webhook():
        """Send a test payload to the configured alert webhook URL."""
        if not settings.alert_webhook_url:
            raise HTTPException(status_code=400, detail="ALERT_WEBHOOK_URL is not configured")
        _send_webhook({
            "recording_id": 0,
            "filename": "test_webhook.wav",
            "mode": "voice",
            "frequency_hz": 145230000.0,
            "frequency_label": "Test signal",
            "timestamp": datetime.utcnow().isoformat(),
            "duration_seconds": 0.0,
            "transcript": "This is a test webhook from the SDR admin panel.",
            "matched": ["keyword:test"],
        })
        return {"message": f"Test webhook sent to {settings.alert_webhook_url}"}


    @router.get("/alert-dryrun")
    async def alert_dryrun(limit: int = 500, db: Session = Depends(get_db)):
        """Check recent recordings against active alert rules without sending webhooks."""
        import re as _re
        from ..services.alerting import _get_rules
        keywords, callsigns = _get_rules(db)
        recordings = (
            db.query(Recording)
            .filter(Recording.transcript.isnot(None), Recording.transcript != "")
            .order_by(Recording.timestamp.desc())
            .limit(limit)
            .all()
        )
        matches = []
        for rec in recordings:
            transcript_lower = rec.transcript.lower()
            callsign_upper = _re.sub(r"[^A-Z0-9]", "", rec.transcript.upper())
            matched = []
            for kw in keywords:
                if kw in transcript_lower:
                    matched.append(f"keyword:{kw}")
            for cs in callsigns:
                if cs in callsign_upper:
                    matched.append(f"callsign:{cs}")
            if matched:
                matches.append({
                    "id": rec.id,
                    "filename": rec.filename,
                    "mode": rec.mode,
                    "frequency_hz": rec.frequency_hz,
                    "frequency_label": rec.frequency_label,
                    "timestamp": rec.timestamp.isoformat() if rec.timestamp else None,
                    "transcript_excerpt": (rec.transcript or "")[:200],
                    "matched_rules": matched,
                })
        return {
            "rules": {"keywords": keywords, "callsigns": callsigns},
            "matches": matches,
            "total": len(matches),
        }


    @router.get("/sdr-live")
    async def sdr_live():
        """Return current FFT detections written by the unified-sdr pod."""
        path = "/data/detections/detections.json"
        if not os.path.exists(path):
            raise HTTPException(status_code=503, detail="Detections file not found — SDR may be offline")
        try:
            with open(path) as f:
                data = json.load(f)
        except Exception as exc:
            raise HTTPException(status_code=500, detail=f"Failed to read detections: {exc}")
        return {
            "center_hz": data.get("center_freq_hz", 0),
            "sample_rate": data.get("sample_rate", 2400000),
            "timestamp": data.get("timestamp"),
            "detections": data.get("detections", []),
        }


    @router.get("/digest-status")
    async def get_digest_status():
        """Return the timestamp of the last sent daily digest."""
        return {
            "last_sent": _last_digest_sent.isoformat() if _last_digest_sent else None,
        }


    @router.post("/send-digest")
    async def send_digest_now(db: Session = Depends(get_db)):
        """Manually trigger a daily digest webhook."""
        global _last_digest_sent
        _send_daily_digest()
        _last_digest_sent = datetime.utcnow()
        return {"status": "sent", "sent_at": _last_digest_sent.isoformat()}
  stats.py: |
    import time
    from fastapi import APIRouter, Depends
    from sqlalchemy import func, text
    from sqlalchemy.orm import Session

    from ..database import get_db
    from ..models import Recording, Repeater

    router = APIRouter()

    _cache: dict = {}
    _CACHE_TTL = 30.0  # seconds


    @router.get("")
    async def get_stats(db: Session = Depends(get_db)):
        now = time.monotonic()
        if _cache.get("ts") and now - _cache["ts"] < _CACHE_TTL:
            return _cache["data"]

        total_recordings = db.query(func.count(Recording.id)).scalar() or 0
        total_duration = db.query(func.sum(Recording.duration_seconds)).scalar() or 0.0

        mode_rows = (
            db.query(Recording.mode, func.count(Recording.id))
            .group_by(Recording.mode)
            .all()
        )
        by_mode = {mode: cnt for mode, cnt in mode_rows}

        transcript_len = func.length(func.trim(func.coalesce(Recording.transcript, "")))
        with_transcript = (
            db.query(func.count(Recording.id)).filter(transcript_len > 0).scalar() or 0
        )

        daily_rows = db.execute(
            text(
                """
                SELECT DATE(timestamp) AS day, COUNT(*) AS cnt
                FROM recordings
                WHERE timestamp >= NOW() - INTERVAL '30 days'
                GROUP BY DATE(timestamp)
                ORDER BY day DESC
                """
            )
        ).fetchall()
        daily = [{"date": str(row.day), "count": row.cnt} for row in daily_rows]

        tag_rows = db.execute(
            text(
                """
                SELECT tag, COUNT(*) AS cnt
                FROM (
                    SELECT json_array_elements_text(ai_tags::json) AS tag
                    FROM recordings
                    WHERE ai_tags IS NOT NULL AND ai_tags <> ''
                ) t
                GROUP BY tag
                ORDER BY cnt DESC
                LIMIT 20
                """
            )
        ).fetchall()
        top_tags = [{"tag": row.tag, "count": row.cnt} for row in tag_rows]

        total_repeaters = db.query(func.count(Repeater.id)).scalar() or 0
        matched_recordings = (
            db.query(func.count(Recording.id))
            .filter(Recording.repeater_id.isnot(None))
            .scalar() or 0
        )

        labeled_recordings = (
            db.query(func.count(Recording.id))
            .filter(Recording.frequency_label.isnot(None))
            .scalar() or 0
        )

        freq_rows = db.execute(
            text(
                """
                SELECT frequency_hz, frequency_label, COUNT(*) AS cnt
                FROM recordings
                WHERE frequency_hz IS NOT NULL
                GROUP BY frequency_hz, frequency_label
                ORDER BY cnt DESC
                LIMIT 10
                """
            )
        ).fetchall()
        top_frequencies = [
            {"frequency_hz": row.frequency_hz, "label": row.frequency_label, "count": row.cnt}
            for row in freq_rows
        ]

        hour_rows = db.execute(
            text(
                """
                SELECT EXTRACT(HOUR FROM timestamp)::int AS hour, COUNT(*) AS cnt
                FROM recordings
                WHERE timestamp >= NOW() - INTERVAL '30 days'
                GROUP BY EXTRACT(HOUR FROM timestamp)::int
                ORDER BY hour
                """
            )
        ).fetchall()
        by_hour_map = {row.hour: row.cnt for row in hour_rows}
        by_hour = [{"hour": h, "count": by_hour_map.get(h, 0)} for h in range(24)]

        cs_rows = db.execute(
            text(
                """
                SELECT tag, COUNT(*) AS cnt
                FROM (
                    SELECT json_array_elements_text(ai_tags::json) AS tag
                    FROM recordings
                    WHERE ai_tags IS NOT NULL AND ai_tags <> ''
                ) t
                WHERE tag ~ '^[AKNW][A-Z0-9]{2,6}$'
                GROUP BY tag
                ORDER BY cnt DESC
                LIMIT 10
                """
            )
        ).fetchall()
        top_callsigns = [{"callsign": row.tag, "count": row.cnt} for row in cs_rows]

        result = {
            "total_recordings": total_recordings,
            "total_duration_seconds": round(total_duration, 1),
            "by_mode": by_mode,
            "with_transcript": with_transcript,
            "without_transcript": total_recordings - with_transcript,
            "with_frequency_label": labeled_recordings,
            "matched_to_repeater": matched_recordings,
            "total_repeaters_known": total_repeaters,
            "daily_last_30": daily,
            "top_tags": top_tags,
            "top_frequencies": top_frequencies,
            "by_hour": by_hour,
            "top_callsigns": top_callsigns,
        }
        _cache["ts"] = now
        _cache["data"] = result
        return result


    @router.get("/activity")
    async def get_activity(days: int = 30, db: Session = Depends(get_db)):
        """
        Frequency × hour-of-day activity heatmap.
        Returns a grid: for each frequency label, the count per hour (0-23).
        """
        rows = db.execute(
            text(
                """
                SELECT
                    COALESCE(frequency_label, 'Unknown') AS label,
                    EXTRACT(HOUR FROM timestamp)::int AS hour,
                    COUNT(*) AS cnt
                FROM recordings
                WHERE timestamp >= NOW() - INTERVAL ':d days'
                  AND timestamp IS NOT NULL
                GROUP BY label, hour
                ORDER BY label, hour
                """.replace(":d", str(int(days)))
            )
        ).fetchall()
        # Pivot: label -> [count_per_hour for hour 0..23]
        grid: dict[str, list[int]] = {}
        totals: dict[str, int] = {}
        for row in rows:
            label = row.label
            if label not in grid:
                grid[label] = [0] * 24
                totals[label] = 0
            grid[label][row.hour] += row.cnt
            totals[label] += row.cnt
        # Sort by total activity descending, cap at top 20
        sorted_labels = sorted(totals.keys(), key=lambda l: totals[l], reverse=True)[:20]
        return {
            "days": days,
            "hours": list(range(24)),
            "series": [
                {"label": lbl, "data": grid[lbl], "total": totals[lbl]}
                for lbl in sorted_labels
            ],
        }

  alerting.py: |
    """
    Webhook alerting for recordings that match watched callsigns or keywords.

    Rules source (in priority order):
      1. DB table `alert_rules` (if any rows exist) — editable via Admin UI
      2. ALERT_KEYWORDS / ALERT_CALLSIGNS env vars (fallback)

    Dedup: checks AlertHistory DB table first (survives restarts), then warms
    the in-process set to avoid repeated DB queries within the same lifecycle.
    """

    import json
    import re
    from urllib import error, request as urllib_request

    from ..config import settings

    _alerted: set[int] = set()


    def _keywords() -> list[str]:
        return [k.strip().lower() for k in settings.alert_keywords.split(",") if k.strip()]


    def _callsigns() -> list[str]:
        return [c.strip().upper() for c in settings.alert_callsigns.split(",") if c.strip()]


    def _get_rules(db=None):
        """Return (keywords, callsigns) — from DB if rules exist, else env vars."""
        if db is not None:
            try:
                from sqlalchemy import text as _text
                rows = db.execute(
                    _text("SELECT rule_type, value FROM alert_rules WHERE enabled = true")
                ).fetchall()
                if rows:
                    kw = [r.value.lower() for r in rows if r.rule_type == "keyword"]
                    cs = [r.value.upper() for r in rows if r.rule_type == "callsign"]
                    return kw, cs
            except Exception:
                pass
        return _keywords(), _callsigns()


    def _send_webhook(payload: dict) -> None:
        body = json.dumps(payload).encode("utf-8")
        req = urllib_request.Request(
            settings.alert_webhook_url,
            data=body,
            headers={"Content-Type": "application/json"},
            method="POST",
        )
        try:
            with urllib_request.urlopen(req, timeout=10):
                pass
        except error.URLError as exc:
            print(f"[Alert] Webhook delivery failed: {exc}")


    def check_alerts(recording, db=None) -> None:
        """Check recording for alert conditions; store to DB and fire webhook if matched."""
        if recording.id in _alerted:
            return

        # Persistent dedup: check AlertHistory in DB (survives pod restarts)
        if db is not None:
            try:
                from ..models import AlertHistory
                if db.query(AlertHistory).filter(
                    AlertHistory.recording_id == recording.id
                ).first():
                    _alerted.add(recording.id)
                    return
            except Exception:
                pass

        if not recording.transcript:
            return

        keywords, callsigns = _get_rules(db)
        transcript_lower = recording.transcript.lower()
        matched: list[str] = []

        for kw in keywords:
            if kw in transcript_lower:
                matched.append(f"keyword:{kw}")

        callsign_upper = re.sub(r"[^A-Z0-9]", "", recording.transcript.upper())
        for cs in callsigns:
            if cs in callsign_upper:
                matched.append(f"callsign:{cs}")

        if not matched:
            return

        _alerted.add(recording.id)

        payload = {
            "recording_id": recording.id,
            "filename": recording.filename,
            "mode": recording.mode,
            "frequency_hz": recording.frequency_hz,
            "frequency_label": recording.frequency_label,
            "timestamp": recording.timestamp.isoformat() if recording.timestamp else None,
            "duration_seconds": recording.duration_seconds,
            "transcript": recording.transcript,
            "matched": matched,
        }

        try:
            from .metrics import alerts_fired as _alerts_fired
            _alerts_fired.inc()
        except Exception:
            pass
        print(f"[Alert] Match for recording {recording.id}: {matched}")

        if db is not None:
            try:
                from ..models import AlertHistory
                ah = AlertHistory(
                    recording_id=recording.id,
                    filename=recording.filename,
                    frequency_hz=recording.frequency_hz,
                    frequency_label=recording.frequency_label,
                    transcript_excerpt=(recording.transcript or "")[:500],
                    matched=json.dumps(matched),
                )
                db.add(ah)
                db.commit()
            except Exception as exc:
                print(f"[Alert] Failed to store alert history: {exc}")
                try:
                    db.rollback()
                except Exception:
                    pass

        if settings.alert_webhook_url:
            _send_webhook(payload)

  metrics.py: |
    from prometheus_client import Counter, Gauge, Histogram

    # Indexer activity counters
    indexer_files_indexed = Counter(
        'sdr_indexer_files_indexed_total',
        'Files indexed by the background indexer',
        ['mode'],
    )
    indexer_files_deleted = Counter(
        'sdr_indexer_files_deleted_total',
        'Recordings auto-deleted during indexing',
        ['reason'],
    )
    indexer_cycle_duration = Histogram(
        'sdr_indexer_cycle_duration_seconds',
        'Duration of a full indexer cycle in seconds',
        buckets=[1, 2, 5, 10, 20, 30, 60, 120],
    )
    indexer_last_run = Gauge(
        'sdr_indexer_last_run_timestamp_seconds',
        'Unix timestamp of last completed indexer cycle',
    )
    indexer_ollama_calls = Counter(
        'sdr_indexer_ollama_calls_total',
        'Ollama API calls made by the indexer',
    )
    indexer_ollama_errors = Counter(
        'sdr_indexer_ollama_errors_total',
        'Ollama API call failures',
    )
    aprs_packets_indexed = Counter(
        'sdr_aprs_packets_indexed_total',
        'APRS packets indexed from text files',
    )
    alerts_fired = Counter(
        'sdr_alerts_fired_total',
        'Webhook alerts fired for matched recordings',
    )

    # DB-level gauges — refreshed once per indexer cycle
    recordings_total = Gauge(
        'sdr_recordings_total',
        'Total recordings in the database',
        ['mode'],
    )
    recordings_with_transcript = Gauge(
        'sdr_recordings_with_transcript_total',
        'Recordings that have a transcript',
    )
    recordings_with_ai_tags = Gauge(
        'sdr_recordings_with_ai_tags_total',
        'Recordings that have AI tags',
    )
    recordings_with_repeater = Gauge(
        'sdr_recordings_with_repeater_total',
        'Recordings matched to a known repeater',
    )
    recordings_pending_transcript = Gauge(
        'sdr_recordings_pending_transcript_total',
        'Voice/CW recordings awaiting transcription',
    )
    recordings_pending_ai_tags = Gauge(
        'sdr_recordings_pending_ai_tags_total',
        'Transcribed recordings awaiting AI tagging',
    )
    recordings_pending_freq_label = Gauge(
        'sdr_recordings_pending_freq_label_total',
        'Recordings with a frequency but no label',
    )
    repeater_count = Gauge(
        'sdr_repeater_count_total',
        'Total repeaters in the local database',
    )
    repeater_sync_age_seconds = Gauge(
        'sdr_repeater_sync_age_seconds',
        'Seconds since the last successful repeater sync',
    )
    sdr_hardware_last_seen_seconds = Gauge(
        'sdr_hardware_last_seen_seconds',
        'Seconds since the most recent audio file from SDR hardware',
    )
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: sdr-viewer-api-overrides
  namespace: sdr-research
